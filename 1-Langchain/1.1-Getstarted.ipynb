{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "##Langsmith Tracking \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x10d898680> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10d88ac90> root_client=<openai.OpenAI object at 0x10bfccf20> root_async_client=<openai.AsyncOpenAI object at 0x10d7f7830> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI refers to artificial intelligence systems designed to function with a degree of autonomy, making decisions and taking actions independently to achieve specific goals. These systems are often characterized by their ability to perceive their environment, interpret data, make decisions, and adjust their behavior based on feedback and changing conditions. Agentic AI can be found in various applications, such as autonomous vehicles, robotic systems, and intelligent virtual assistants. The term emphasizes the AI's capability to act as an \"agent,\" which means it operates proactively and adaptively to fulfill tasks rather than simply following pre-programmed instructions or responding reactively to specific inputs.\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the asked question '), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the asked question \"),\n",
    "        (\"user\",\"{input}\")\n",
    "\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n",
    "#system is the instruction given to the LLM \n",
    "# and user is the input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langchain is a framework specifically designed for building applications powered by large language models (LLMs). It provides an architecture that simplifies and enhances the process of interacting with LLMs through structured workflows, allowing developers to create applications that are more robust, efficient, and scalable.\\n\\nThe key components of Langchain include:\\n\\n1. **Prompt Management**: It allows developers to manage and manipulate the prompts sent to LLMs effectively. This includes dynamic prompt construction, templating, and chaining multiple prompts together to get more refined responses.\\n\\n2. **Chains**: Langchain introduces the concept of chains, where multiple calls to LLMs can be strung together in a sequence. This makes complex workflows—with logical decision-making and branching—possible, which is useful in applications like conversational agents, data processing pipelines, etc.\\n\\n3. **Memory**: The framework allows developers to implement memory in conversational applications, meaning the system can \"remember\" the context from previous interactions, making conversations more coherent and contextually aware.\\n\\n4. **Agents**: Langchain includes agents that can automatically decide which actions to take based on the input and intermediate outputs. This is useful for applications that need dynamic, context-driven decision-making.\\n\\n5. **Data Loaders**: For information retrieval and processing, Langchain supports integration with various data sources, allowing seamless ingestion of knowledge bases or documents into LLM workflows.\\n\\nLangchain supports a variety of integrations to extend its functionality:\\n\\n1. **LLM Providers**: Integration with multiple LLM providers such as OpenAI\\'s GPT, Hugging Face models, and other proprietary APIs, allowing developers to choose the model that best suits their needs.\\n\\n2. **Vector Stores**: Langchain can integrate with vector search engines like Pinecone, Weaviate, or FAISS, enabling the use of vectorized data for efficient similarity search and retrieval-augmented generation.\\n\\n3. **Databases**: It supports SQL and NoSQL databases for storing and retrieving data, facilitating applications that require backend data persistence and large-scale data processing.\\n\\n4. **APIs**: Integration with external APIs can be set up for accessing various web services, thereby expanding the applicability of Langchain in tasks like information retrieval from the web or dynamic data access.\\n\\n5. **Web Scraping**: With libraries and connectors, Langchain can perform web scraping tasks which are then used as inputs or background data for language models.\\n\\n6. **Cloud Services**: Langchain can be deployed and managed across various cloud services, enabling scalable deployment of AI applications.\\n\\n7. **Tools and Platforms**: The framework can work with popular machine learning platforms and tools, including for monitoring and experimentation, which helps in testing and improving model performance.\\n\\nLangchain\\'s architecture and integrations are designed to help developers rapidly prototype, experiment with, and deploy AI applications that leverage the power of large language models in versatile and comprehensive ways.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 582, 'prompt_tokens': 47, 'total_tokens': 629, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None} id='run-d27010e9-3121-41c9-ad7d-37184638aeab-0' usage_metadata={'input_tokens': 47, 'output_tokens': 582, 'total_tokens': 629, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me in detail what langchain is used for explain all the integrations which Langchain has\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langchain is a framework specifically designed for building applications powered by large language models (LLMs). It provides an architecture that simplifies and enhances the process of interacting with LLMs through structured workflows, allowing developers to create applications that are more robust, efficient, and scalable.\n",
      "\n",
      "The key components of Langchain include:\n",
      "\n",
      "1. **Prompt Management**: It allows developers to manage and manipulate the prompts sent to LLMs effectively. This includes dynamic prompt construction, templating, and chaining multiple prompts together to get more refined responses.\n",
      "\n",
      "2. **Chains**: Langchain introduces the concept of chains, where multiple calls to LLMs can be strung together in a sequence. This makes complex workflows—with logical decision-making and branching—possible, which is useful in applications like conversational agents, data processing pipelines, etc.\n",
      "\n",
      "3. **Memory**: The framework allows developers to implement memory in conversational applications, meaning the system can \"remember\" the context from previous interactions, making conversations more coherent and contextually aware.\n",
      "\n",
      "4. **Agents**: Langchain includes agents that can automatically decide which actions to take based on the input and intermediate outputs. This is useful for applications that need dynamic, context-driven decision-making.\n",
      "\n",
      "5. **Data Loaders**: For information retrieval and processing, Langchain supports integration with various data sources, allowing seamless ingestion of knowledge bases or documents into LLM workflows.\n",
      "\n",
      "Langchain supports a variety of integrations to extend its functionality:\n",
      "\n",
      "1. **LLM Providers**: Integration with multiple LLM providers such as OpenAI's GPT, Hugging Face models, and other proprietary APIs, allowing developers to choose the model that best suits their needs.\n",
      "\n",
      "2. **Vector Stores**: Langchain can integrate with vector search engines like Pinecone, Weaviate, or FAISS, enabling the use of vectorized data for efficient similarity search and retrieval-augmented generation.\n",
      "\n",
      "3. **Databases**: It supports SQL and NoSQL databases for storing and retrieving data, facilitating applications that require backend data persistence and large-scale data processing.\n",
      "\n",
      "4. **APIs**: Integration with external APIs can be set up for accessing various web services, thereby expanding the applicability of Langchain in tasks like information retrieval from the web or dynamic data access.\n",
      "\n",
      "5. **Web Scraping**: With libraries and connectors, Langchain can perform web scraping tasks which are then used as inputs or background data for language models.\n",
      "\n",
      "6. **Cloud Services**: Langchain can be deployed and managed across various cloud services, enabling scalable deployment of AI applications.\n",
      "\n",
      "7. **Tools and Platforms**: The framework can work with popular machine learning platforms and tools, including for monitoring and experimentation, which helps in testing and improving model performance.\n",
      "\n",
      "Langchain's architecture and integrations are designed to help developers rapidly prototype, experiment with, and deploy AI applications that leverage the power of large language models in versatile and comprehensive ways.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a specialized platform and toolkit developed by LangChain, designed to facilitate the development and evaluation of applications that rely on Language Learning Models (LLMs) and AI agents. It is particularly focused on improving the observability, testing, and evaluation processes for such applications. Langsmith provides capabilities to track and refine the performance of LLMs, making it a valuable resource for developers who need to ensure the reliability and effectiveness of their AI-driven applications. The platform integrates with LangChain's broader ecosystem and supports detailed logging, analytics, and feedback mechanisms that help developers iterate on their models with greater precision and insight.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt|llm|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=WebBaseLoader(\"https://python.langchain.com/docs/tutorials/agents/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\\n\\n\\n\\n\\nBuild an Agent | 🦜️🔗 LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain\\'s stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data directly to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild an AgentOn this pageBuild an Agent\\nBy themselves, language models can\\'t take actions - they just output text.\\nA big use case for LangChain is creating agents.\\nAgents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action.\\nAfter executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling.\\nIn this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it.\\nEnd-to-end agent\\u200b\\nThe code snippet below represents a fully functional agent that uses an LLM to decide which tools to use. It is equipped with a generic search tool. It has conversational memory - meaning that it can be used as a multi-turn chatbot.\\nIn the rest of the guide, we will walk through the individual components and what each part does - but if you want to just grab some code and get started, feel free to use this!\\n# Import relevant functionalityfrom langchain_anthropic import ChatAnthropicfrom langchain_community.tools.tavily_search import TavilySearchResultsfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.prebuilt import create_react_agent# Create the agentmemory = MemorySaver()model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")search = TavilySearchResults(max_results=2)tools = [search]agent_executor = create_react_agent(model, tools, checkpointer=memory)# Use the agentconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]}, config):    print(chunk)    print(\"----\")for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]}, config):    print(chunk)    print(\"----\")API Reference:ChatAnthropic | TavilySearchResults | HumanMessage | MemorySaver | create_react_agent\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"Hello Bob! Since you didn\\'t ask a specific question, I don\\'t need to use any tools to respond. It\\'s nice to meet you. San Francisco is a wonderful city with lots to see and do. I hope you\\'re enjoying living there. Please let me know if you have any other questions!\", response_metadata={\\'id\\': \\'msg_01Mmfzfs9m4XMgVzsCZYMWqH\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 271, \\'output_tokens\\': 65}}, id=\\'run-44c57f9c-a637-4888-b7d9-6d985031ae48-0\\', usage_metadata={\\'input_tokens\\': 271, \\'output_tokens\\': 65, \\'total_tokens\\': 336})]}}----{\\'agent\\': {\\'messages\\': [AIMessage(content=[{\\'text\\': \\'To get current weather information for your location in San Francisco, let me invoke the search tool:\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01BGEyQaSz3pTq8RwUUHSRoo\\', \\'input\\': {\\'query\\': \\'san francisco weather\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}], response_metadata={\\'id\\': \\'msg_013AVSVsRLKYZjduLpJBY4us\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'tool_use\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 347, \\'output_tokens\\': 80}}, id=\\'run-de7923b6-5ee2-4ebe-bd95-5aed4933d0e3-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'san francisco weather\\'}, \\'id\\': \\'toolu_01BGEyQaSz3pTq8RwUUHSRoo\\'}], usage_metadata={\\'input_tokens\\': 347, \\'output_tokens\\': 80, \\'total_tokens\\': 427})]}}----{\\'tools\\': {\\'messages\\': [ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1717238643, \\\\\\'localtime\\\\\\': \\\\\\'2024-06-01 3:44\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1717237800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-06-01 03:30\\\\\\', \\\\\\'temp_c\\\\\\': 12.0, \\\\\\'temp_f\\\\\\': 53.6, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Mist\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/143.png\\\\\\', \\\\\\'code\\\\\\': 1030}, \\\\\\'wind_mph\\\\\\': 5.6, \\\\\\'wind_kph\\\\\\': 9.0, \\\\\\'wind_degree\\\\\\': 310, \\\\\\'wind_dir\\\\\\': \\\\\\'NW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1013.0, \\\\\\'pressure_in\\\\\\': 29.92, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 88, \\\\\\'cloud\\\\\\': 100, \\\\\\'feelslike_c\\\\\\': 10.5, \\\\\\'feelslike_f\\\\\\': 50.8, \\\\\\'windchill_c\\\\\\': 9.3, \\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\': 20.1}}\"}, {\"url\": \"https://www.timeanddate.com/weather/usa/san-francisco/historic\", \"content\": \"Past Weather in San Francisco, California, USA \\\\\\\\u2014 Yesterday and Last 2 Weeks. Time/General. Weather. Time Zone. DST Changes. Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 68 \\\\\\\\u00b0F. Passing clouds.\"}]\\', name=\\'tavily_search_results_json\\', tool_call_id=\\'toolu_01BGEyQaSz3pTq8RwUUHSRoo\\')]}}----{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'Based on the search results, the current weather in San Francisco is:\\\\n\\\\nTemperature: 53.6°F (12°C)\\\\nConditions: Misty\\\\nWind: 5.6 mph (9 kph) from the Northwest\\\\nHumidity: 88%\\\\nCloud Cover: 100% \\\\n\\\\nThe results provide detailed information like wind chill, heat index, visibility and more. It looks like a typical cool, foggy morning in San Francisco. Let me know if you need any other details about the weather where you live!\\', response_metadata={\\'id\\': \\'msg_019WGLbaojuNdbCnqac7zaGW\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1035, \\'output_tokens\\': 120}}, id=\\'run-1bb68bf3-b212-4ef4-8a31-10c830421c78-0\\', usage_metadata={\\'input_tokens\\': 1035, \\'output_tokens\\': 120, \\'total_tokens\\': 1155})]}}----\\nSetup\\u200b\\nJupyter Notebook\\u200b\\nThis guide (and most of the other guides in the documentation) uses Jupyter notebooks and assumes the reader is as well. Jupyter notebooks are perfect interactive environments for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc), and observing these cases is a great way to better understand building with LLMs.\\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebook. See here for instructions on how to install.\\nInstallation\\u200b\\nTo install LangChain run:\\n%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite\\nFor more details, see our Installation guide.\\nLangSmith\\u200b\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\\nThe best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nexport LANGSMITH_TRACING=\"true\"export LANGSMITH_API_KEY=\"...\"\\nOr, if in a notebook, you can set them with:\\nimport getpassimport osos.environ[\"LANGSMITH_TRACING\"] = \"true\"os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\\nTavily\\u200b\\nWe will be using Tavily (a search engine) as a tool.\\nIn order to use it, you will need to get and set an API key:\\nexport TAVILY_API_KEY=\"...\"\\nOr, if in a notebook, you can set it with:\\nimport getpassimport osos.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\\nDefine tools\\u200b\\nWe first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool.\\nfrom langchain_community.tools.tavily_search import TavilySearchResultssearch = TavilySearchResults(max_results=2)search_results = search.invoke(\"what is the weather in SF\")print(search_results)# If we want, we can create other tools.# Once we have all the tools we want, we can put them in a list that we will reference later.tools = [search]API Reference:TavilySearchResults\\n[{\\'url\\': \\'https://www.weatherapi.com/\\',  \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717238703, \\'localtime\\': \\'2024-06-01 3:45\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717237800, \\'last_updated\\': \\'2024-06-01 03:30\\', \\'temp_c\\': 12.0, \\'temp_f\\': 53.6, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 310, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.92, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 88, \\'cloud\\': 100, \\'feelslike_c\\': 10.5, \\'feelslike_f\\': 50.8, \\'windchill_c\\': 9.3, \\'windchill_f\\': 48.7, \\'heatindex_c\\': 11.1, \\'heatindex_f\\': 51.9, \\'dewpoint_c\\': 8.8, \\'dewpoint_f\\': 47.8, \\'vis_km\\': 6.4, \\'vis_miles\\': 3.0, \\'uv\\': 1.0, \\'gust_mph\\': 12.5, \\'gust_kph\\': 20.1}}\"}, {\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/san-francisco/date/2024-01-06\\',  \\'content\\': \\'Current Weather for Popular Cities . San Francisco, CA 58 ° F Partly Cloudy; Manhattan, NY warning 51 ° F Cloudy; Schiller Park, IL (60176) warning 51 ° F Fair; Boston, MA warning 41 ° F ...\\'}]\\nUsing Language Models\\u200b\\nNext, let\\'s learn how to use a language model to call tools. LangChain supports many different language models that you can use interchangably - select the one you want to use below!\\n\\nSelect chat model:Groq▾GroqOpenAIAnthropicAzureGoogleAWSCohereNVIDIAFireworks AIMistral AITogether AIDatabrickspip install -qU langchain-groqimport getpassimport osif not os.environ.get(\"GROQ_API_KEY\"):  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")from langchain_groq import ChatGroqmodel = ChatGroq(model=\"llama3-8b-8192\")\\nYou can call the language model by passing in a list of messages. By default, the response is a content string.\\nfrom langchain_core.messages import HumanMessageresponse = model.invoke([HumanMessage(content=\"hi!\")])response.contentAPI Reference:HumanMessage\\n\\'Hi there!\\'\\nWe can now see what it is like to enable this model to do tool calling. In order to enable that we use .bind_tools to give the language model knowledge of these tools\\nmodel_with_tools = model.bind_tools(tools)\\nWe can now call the model. Let\\'s first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: Hello!ToolCalls: []\\nNow, let\\'s try calling it with some input that would expect a tool to be called.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"What\\'s the weather in SF?\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: ToolCalls: [{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather san francisco\\'}, \\'id\\': \\'toolu_01VTP7DUvSfgtYxsq9x4EwMp\\'}]\\nWe can see that there\\'s now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\\nThis isn\\'t calling that tool yet - it\\'s just telling us to. In order to actually call it, we\\'ll want to create our agent.\\nCreate the agent\\u200b\\nNow that we have defined the tools and the LLM, we can create the agent. We will be using LangGraph to construct the agent.\\nCurrently, we are using a high level interface to construct the agent, but the nice thing about LangGraph is that this high-level interface is backed by a low-level, highly controllable API in case you want to modify the agent logic.\\nNow, we can initialize the agent with the LLM and the tools.\\nNote that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood.\\nfrom langgraph.prebuilt import create_react_agentagent_executor = create_react_agent(model, tools)API Reference:create_react_agent\\nRun the agent\\u200b\\nWe can now run the agent with a few queries! Note that for now, these are all stateless queries (it won\\'t remember previous interactions). Note that the agent will return the final state at the end of the interaction (which includes any inputs, we will see later on how to get only the outputs).\\nFirst up, let\\'s see how it responds when there\\'s no need to call a tool:\\nresponse = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})response[\"messages\"]\\n[HumanMessage(content=\\'hi!\\', id=\\'a820fcc5-9b87-457a-9af0-f21768143ee3\\'), AIMessage(content=\\'Hello!\\', response_metadata={\\'id\\': \\'msg_01VbC493X1VEDyusgttiEr1z\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 264, \\'output_tokens\\': 5}}, id=\\'run-0e0ddae8-a85b-4bd6-947c-c36c857a4698-0\\', usage_metadata={\\'input_tokens\\': 264, \\'output_tokens\\': 5, \\'total_tokens\\': 269})]\\nIn order to see exactly what is happening under the hood (and to make sure it\\'s not calling a tool) we can take a look at the LangSmith trace\\nLet\\'s now try it out on an example where it should be invoking the tool\\nresponse = agent_executor.invoke(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]})response[\"messages\"]\\n[HumanMessage(content=\\'whats the weather in sf?\\', id=\\'1d6c96bb-4ddb-415c-a579-a07d5264de0d\\'), AIMessage(content=[{\\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\', \\'input\\': {\\'query\\': \\'weather in san francisco\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}], response_metadata={\\'id\\': \\'msg_0132wQUcEduJ8UKVVVqwJzM4\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'tool_use\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 269, \\'output_tokens\\': 61}}, id=\\'run-26d5e5e8-d4fd-46d2-a197-87b95b10e823-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather in san francisco\\'}, \\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'}], usage_metadata={\\'input_tokens\\': 269, \\'output_tokens\\': 61, \\'total_tokens\\': 330}), ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1717238703, \\\\\\'localtime\\\\\\': \\\\\\'2024-06-01 3:45\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1717237800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-06-01 03:30\\\\\\', \\\\\\'temp_c\\\\\\': 12.0, \\\\\\'temp_f\\\\\\': 53.6, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Mist\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/143.png\\\\\\', \\\\\\'code\\\\\\': 1030}, \\\\\\'wind_mph\\\\\\': 5.6, \\\\\\'wind_kph\\\\\\': 9.0, \\\\\\'wind_degree\\\\\\': 310, \\\\\\'wind_dir\\\\\\': \\\\\\'NW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1013.0, \\\\\\'pressure_in\\\\\\': 29.92, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 88, \\\\\\'cloud\\\\\\': 100, \\\\\\'feelslike_c\\\\\\': 10.5, \\\\\\'feelslike_f\\\\\\': 50.8, \\\\\\'windchill_c\\\\\\': 9.3, \\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\': 20.1}}\"}, {\"url\": \"https://www.timeanddate.com/weather/usa/san-francisco/hourly\", \"content\": \"Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 59 \\\\\\\\u00b0F. Passing clouds. (Weather station: San Francisco International Airport, USA). See more current weather.\"}]\\', name=\\'tavily_search_results_json\\', id=\\'37aa1fd9-b232-4a02-bd22-bc5b9b44a22c\\', tool_call_id=\\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'), AIMessage(content=\\'Based on the search results, here is a summary of the current weather in San Francisco:\\\\n\\\\nThe weather in San Francisco is currently misty with a temperature of around 53°F (12°C). There is complete cloud cover and moderate winds from the northwest around 5-9 mph (9-14 km/h). Humidity is high at 88%. Visibility is around 3 miles (6.4 km). \\\\n\\\\nThe results provide an hourly forecast as well as current conditions from a couple different weather sources. Let me know if you need any additional details about the San Francisco weather!\\', response_metadata={\\'id\\': \\'msg_01BRX9mrT19nBDdHYtR7wJ92\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 920, \\'output_tokens\\': 132}}, id=\\'run-d0325583-3ddc-4432-b2b2-d023eb97660f-0\\', usage_metadata={\\'input_tokens\\': 920, \\'output_tokens\\': 132, \\'total_tokens\\': 1052})]\\nWe can check out the LangSmith trace to make sure it\\'s calling the search tool effectively.\\nStreaming Messages\\u200b\\nWe\\'ve seen how the agent can be called with .invoke to get  a final response. If the agent executes multiple steps, this may take a while. To show intermediate progress, we can stream back messages as they occur.\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'\\', additional_kwargs={\\'tool_calls\\': [{\\'id\\': \\'call_50Kb8zHmFqPYavQwF5TgcOH8\\', \\'function\\': {\\'arguments\\': \\'{\\\\n  \"query\": \"current weather in San Francisco\"\\\\n}\\', \\'name\\': \\'tavily_search_results_json\\'}, \\'type\\': \\'function\\'}]}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 23, \\'prompt_tokens\\': 134, \\'total_tokens\\': 157}, \\'model_name\\': \\'gpt-4\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'tool_calls\\', \\'logprobs\\': None}, id=\\'run-042d5feb-c2cc-4c3f-b8fd-dbc22fd0bc07-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'current weather in San Francisco\\'}, \\'id\\': \\'call_50Kb8zHmFqPYavQwF5TgcOH8\\'}])]}}----{\\'action\\': {\\'messages\\': [ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1714426906, \\\\\\'localtime\\\\\\': \\\\\\'2024-04-29 14:41\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1714426200, \\\\\\'last_updated\\\\\\': \\\\\\'2024-04-29 14:30\\\\\\', \\\\\\'temp_c\\\\\\': 17.8, \\\\\\'temp_f\\\\\\': 64.0, \\\\\\'is_day\\\\\\': 1, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Sunny\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/day/113.png\\\\\\', \\\\\\'code\\\\\\': 1000}, \\\\\\'wind_mph\\\\\\': 23.0, \\\\\\'wind_kph\\\\\\': 37.1, \\\\\\'wind_degree\\\\\\': 290, \\\\\\'wind_dir\\\\\\': \\\\\\'WNW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1019.0, \\\\\\'pressure_in\\\\\\': 30.09, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 50, \\\\\\'cloud\\\\\\': 0, \\\\\\'feelslike_c\\\\\\': 17.8, \\\\\\'feelslike_f\\\\\\': 64.0, \\\\\\'vis_km\\\\\\': 16.0, \\\\\\'vis_miles\\\\\\': 9.0, \\\\\\'uv\\\\\\': 5.0, \\\\\\'gust_mph\\\\\\': 27.5, \\\\\\'gust_kph\\\\\\': 44.3}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/april-2024/\", \"content\": \"Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30 days Year. Detailed \\\\\\\\u26a1 San Francisco Weather Forecast for April 2024 - day/night \\\\\\\\ud83c\\\\\\\\udf21\\\\\\\\ufe0f temperatures, precipitations - World-Weather.info.\"}]\\', name=\\'tavily_search_results_json\\', id=\\'d88320ac-3fe1-4f73-870a-3681f15f6982\\', tool_call_id=\\'call_50Kb8zHmFqPYavQwF5TgcOH8\\')]}}----{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'The current weather in San Francisco, California is sunny with a temperature of 17.8°C (64.0°F). The wind is coming from the WNW at 23.0 mph. The humidity is at 50%. [source](https://www.weatherapi.com/)\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 58, \\'prompt_tokens\\': 602, \\'total_tokens\\': 660}, \\'model_name\\': \\'gpt-4\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-0cd2a507-ded5-4601-afe3-3807400e9989-0\\')]}}----\\nStreaming tokens\\u200b\\nIn addition to streaming back messages, it is also useful to stream back tokens.\\nWe can do this with the .astream_events method.\\nimportantThis .astream_events method only works with Python 3.11 or higher.\\nasync for event in agent_executor.astream_events(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"):    kind = event[\"event\"]    if kind == \"on_chain_start\":        if (            event[\"name\"] == \"Agent\"        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`            print(                f\"Starting agent: {event[\\'name\\']} with input: {event[\\'data\\'].get(\\'input\\')}\"            )    elif kind == \"on_chain_end\":        if (            event[\"name\"] == \"Agent\"        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`            print()            print(\"--\")            print(                f\"Done agent: {event[\\'name\\']} with output: {event[\\'data\\'].get(\\'output\\')[\\'output\\']}\"            )    if kind == \"on_chat_model_stream\":        content = event[\"data\"][\"chunk\"].content        if content:            # Empty content in the context of OpenAI means            # that the model is asking for a tool to be invoked.            # So we only print non-empty content            print(content, end=\"|\")    elif kind == \"on_tool_start\":        print(\"--\")        print(            f\"Starting tool: {event[\\'name\\']} with inputs: {event[\\'data\\'].get(\\'input\\')}\"        )    elif kind == \"on_tool_end\":        print(f\"Done tool: {event[\\'name\\']}\")        print(f\"Tool output was: {event[\\'data\\'].get(\\'output\\')}\")        print(\"--\")\\n--Starting tool: tavily_search_results_json with inputs: {\\'query\\': \\'current weather in San Francisco\\'}Done tool: tavily_search_results_jsonTool output was: [{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714427052, \\'localtime\\': \\'2024-04-29 14:44\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714426200, \\'last_updated\\': \\'2024-04-29 14:30\\', \\'temp_c\\': 17.8, \\'temp_f\\': 64.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 23.0, \\'wind_kph\\': 37.1, \\'wind_degree\\': 290, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1019.0, \\'pressure_in\\': 30.09, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 50, \\'cloud\\': 0, \\'feelslike_c\\': 17.8, \\'feelslike_f\\': 64.0, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 27.5, \\'gust_kph\\': 44.3}}\"}, {\\'url\\': \\'https://www.weathertab.com/en/c/e/04/united-states/california/san-francisco/\\', \\'content\\': \\'San Francisco Weather Forecast for Apr 2024 - Risk of Rain Graph. Rain Risk Graph: Monthly Overview. Bar heights indicate rain risk percentages. Yellow bars mark low-risk days, while black and grey bars signal higher risks. Grey-yellow bars act as buffers, advising to keep at least one day clear from the riskier grey and black days, guiding ...\\'}]--The| current| weather| in| San| Francisco|,| California|,| USA| is| sunny| with| a| temperature| of| |17|.|8|°C| (|64|.|0|°F|).| The| wind| is| blowing| from| the| W|NW| at| a| speed| of| |37|.|1| k|ph| (|23|.|0| mph|).| The| humidity| level| is| at| |50|%.| [|Source|](|https|://|www|.weather|api|.com|/)|\\nAdding in memory\\u200b\\nAs mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from).\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()API Reference:MemorySaver\\nagent_executor = create_react_agent(model, tools, checkpointer=memory)config = {\"configurable\": {\"thread_id\": \"abc123\"}}\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"Hello Bob! It\\'s nice to meet you again.\", response_metadata={\\'id\\': \\'msg_013C1z2ZySagEFwmU1EsysR2\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1162, \\'output_tokens\\': 14}}, id=\\'run-f878acfd-d195-44e8-9166-e2796317e3f8-0\\', usage_metadata={\\'input_tokens\\': 1162, \\'output_tokens\\': 14, \\'total_tokens\\': 1176})]}}----\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'You mentioned your name is Bob when you introduced yourself earlier. So your name is Bob.\\', response_metadata={\\'id\\': \\'msg_01WNwnRNGwGDRw6vRdivt6i1\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1184, \\'output_tokens\\': 21}}, id=\\'run-f5c0b957-8878-405a-9d4b-a7cd38efe81f-0\\', usage_metadata={\\'input_tokens\\': 1184, \\'output_tokens\\': 21, \\'total_tokens\\': 1205})]}}----\\nExample LangSmith trace\\nIf you want to start a new conversation, all you have to do is change the thread_id used\\nconfig = {\"configurable\": {\"thread_id\": \"xyz123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"I\\'m afraid I don\\'t actually know your name. As an AI assistant without personal information about you, I don\\'t have a specific name associated with our conversation.\", response_metadata={\\'id\\': \\'msg_01NoaXNNYZKSoBncPcLkdcbo\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 267, \\'output_tokens\\': 36}}, id=\\'run-c9f7df3d-525a-4d8f-bbcf-a5b4a5d2e4b0-0\\', usage_metadata={\\'input_tokens\\': 267, \\'output_tokens\\': 36, \\'total_tokens\\': 303})]}}----\\nConclusion\\u200b\\nThat\\'s a wrap! In this quick start we covered how to create a simple agent.\\nWe\\'ve then shown how to stream back a response - not only with the intermediate steps, but also tokens!\\nWe\\'ve also added in memory so you can have a conversation with them.\\nAgents are a complex topic with lots to learn!\\nFor more information on Agents, please check out the LangGraph documentation. This has it\\'s own set of concepts, tutorials, and how-to guides.Edit this pageWas this page helpful?PreviousBuild an Extraction ChainNextTaggingEnd-to-end agentSetupJupyter NotebookInstallationLangSmithTavilyDefine toolsUsing Language ModelsCreate the agentRun the agentStreaming MessagesStreaming tokensAdding in memoryConclusionCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document=loader.load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Build an Agent | 🦜️🔗 LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Skip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1💬SearchIntroductionTutorialsBuild a Question Answering application over a Graph DatabaseTutorialsBuild a simple LLM application with chat models and prompt templatesBuild a ChatbotBuild a Retrieval Augmented Generation (RAG) App: Part 2Build an Extraction ChainBuild an AgentTaggingBuild a Retrieval Augmented Generation (RAG) App: Part 1Build a semantic search engineBuild a Question/Answering system over SQL dataSummarize TextHow-to guidesHow-to guidesHow to use tools in a chainHow to use a vectorstore as a retrieverHow to add memory to chatbotsHow to use example selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='selectorsHow to add a semantic layer over graph databaseHow to invoke runnables in parallelHow to stream chat model responsesHow to add default invocation args to a RunnableHow to add retrieval to chatbotsHow to use few shot examples in chat modelsHow to do tool/function callingHow to install LangChain packagesHow to add examples to the prompt for query analysisHow to use few shot examplesHow to run custom functionsHow to use output parsers to parse an LLM response into structured formatHow to handle cases where no queries are generatedHow to route between sub-chainsHow to return structured data from a modelHow to summarize text through parallelizationHow to summarize text through iterative refinementHow to summarize text in a single LLM callHow to use toolkitsHow to add ad-hoc tool calling capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"capability to LLMs and Chat ModelsBuild an Agent with AgentExecutor (Legacy)How to construct knowledge graphsHow to partially format prompt templatesHow to handle multiple queries when doing query analysisHow to use built-in tools and toolkitsHow to pass through arguments from one step to the nextHow to compose prompts togetherHow to handle multiple retrievers when doing query analysisHow to add values to a chain's stateHow to construct filters for query analysisHow to configure runtime chain internalsHow deal with high cardinality categoricals when doing query analysisCustom Document LoaderHow to use the MultiQueryRetrieverHow to add scores to retriever resultsCachingHow to use callbacks in async environmentsHow to attach callbacks to a runnableHow to propagate callbacks  constructorHow to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='to dispatch custom callback eventsHow to pass callbacks in at runtimeHow to split by characterHow to cache chat model responsesHow to handle rate limitsHow to init any model in one lineHow to track token usage in ChatModelsHow to add tools to chatbotsHow to split codeHow to do retrieval with contextual compressionHow to convert Runnables to ToolsHow to create custom callback handlersHow to create a custom chat model classCustom EmbeddingsHow to create a custom LLM classCustom RetrieverHow to create toolsHow to debug your LLM appsHow to load CSVsHow to load documents from a directoryHow to load HTMLHow to load JSONHow to load MarkdownHow to load Microsoft Office filesHow to load PDFsHow to load web pagesHow to create a dynamic (self-constructing) chainText embedding modelsHow to combine results from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='from multiple retrieversHow to select examples from a LangSmith datasetHow to select examples by lengthHow to select examples by maximal marginal relevance (MMR)How to select examples by n-gram overlapHow to select examples by similarityHow to use reference examples when doing extractionHow to handle long text when doing extractionHow to use prompting alone (no tool calling) to do extractionHow to add fallbacks to a runnableHow to filter messagesHybrid SearchHow to use the LangChain indexing APIHow to inspect runnablesLangChain Expression Language CheatsheetHow to cache LLM responsesHow to track token usage for LLMsRun models locallyHow to get log probabilitiesHow to reorder retrieved results to mitigate the \"lost in the middle\" effectHow to split Markdown by HeadersHow to merge consecutive messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data directly to'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='messages of the same typeHow to add message historyHow to migrate from legacy LangChain agents to LangGraphHow to retrieve using multiple vectors per documentHow to pass multimodal data directly to modelsHow to use multimodal promptsHow to create a custom Output ParserHow to use the output-fixing parserHow to parse JSON outputHow to retry when a parsing error occursHow to parse text from message objectsHow to parse XML outputHow to parse YAML outputHow to use the Parent Document RetrieverHow to use LangChain with different Pydantic versionsHow to add chat historyHow to get a RAG application to add citationsHow to do per-user retrievalHow to get your RAG application to return sourcesHow to stream results from your RAG applicationHow to split JSON dataHow to recursively split text by charactersResponse metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='metadataHow to pass runtime secrets to runnablesHow to do \"self-querying\" retrievalHow to split text based on semantic similarityHow to chain runnablesHow to save and load LangChain objectsHow to split text by tokensHow to split HTMLHow to do question answering over CSVsHow to deal with large databases when doing SQL question-answeringHow to better prompt when doing SQL question-answeringHow to do query validation as part of SQL question-answeringHow to stream runnablesHow to stream responses from an LLMHow to use a time-weighted vector store retrieverHow to return artifacts from a toolHow to use chat models to call toolsHow to disable parallel tool callingHow to force models to call a toolHow to access the RunnableConfig from a toolHow to pass tool outputs to chat modelsHow to pass run time values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='values to toolsHow to stream events from a toolHow to stream tool callsHow to convert tools to OpenAI FunctionsHow to handle tool errorsHow to use few-shot prompting with tool callingHow to add a human-in-the-loop for toolsHow to bind model-specific toolsHow to trim messagesHow to create and query vector storesConceptual guideAgentsArchitectureAsync programming with langchainCallbacksChat historyChat modelsDocument loadersEmbedding modelsEvaluationExample selectorsFew-shot promptingConceptual guideKey-value storesLangChain Expression Language (LCEL)MessagesMultimodalityOutput parsersPrompt TemplatesRetrieval augmented generation (RAG)RetrievalRetrieversRunnable interfaceStreamingStructured outputsTestingString-in, string-out llmsText splittersTokensTool callingToolsTracingVector storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='storesWhy LangChain?Ecosystem🦜🛠️ LangSmith🦜🕸️ LangGraphVersionsv0.3v0.2Pydantic compatibilityMigrating from v0.0 chainsHow to migrate from v0.0 chainsMigrating from ConstitutionalChainMigrating from ConversationalChainMigrating from ConversationalRetrievalChainMigrating from LLMChainMigrating from LLMMathChainMigrating from LLMRouterChainMigrating from MapReduceDocumentsChainMigrating from MapRerankDocumentsChainMigrating from MultiPromptChainMigrating from RefineDocumentsChainMigrating from RetrievalQAMigrating from StuffDocumentsChainUpgrading to LangGraph memoryHow to migrate to LangGraph memoryHow to use BaseChatMessageHistory with LangGraphMigrating off ConversationBufferMemory or ConversationStringBufferMemoryMigrating off ConversationBufferWindowMemory or ConversationTokenBufferMemoryMigrating off ConversationSummaryMemory or ConversationSummaryBufferMemoryA Long-Term Memory AgentRelease policySecurity PolicyTutorialsBuild an AgentOn this pageBuild an Agent'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"By themselves, language models can't take actions - they just output text.\\nA big use case for LangChain is creating agents.\\nAgents are systems that use LLMs as reasoning engines to determine which actions to take and the inputs necessary to perform the action.\\nAfter executing actions, the results can be fed back into the LLM to determine whether more actions are needed, or whether it is okay to finish. This is often achieved via tool-calling.\\nIn this tutorial we will build an agent that can interact with a search engine. You will be able to ask this agent questions, watch it call the search tool, and have conversations with it.\\nEnd-to-end agent\\u200b\\nThe code snippet below represents a fully functional agent that uses an LLM to decide which tools to use. It is equipped with a generic search tool. It has conversational memory - meaning that it can be used as a multi-turn chatbot.\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='In the rest of the guide, we will walk through the individual components and what each part does - but if you want to just grab some code and get started, feel free to use this!'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='# Import relevant functionalityfrom langchain_anthropic import ChatAnthropicfrom langchain_community.tools.tavily_search import TavilySearchResultsfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.prebuilt import create_react_agent# Create the agentmemory = MemorySaver()model = ChatAnthropic(model_name=\"claude-3-sonnet-20240229\")search = TavilySearchResults(max_results=2)tools = [search]agent_executor = create_react_agent(model, tools, checkpointer=memory)# Use the agentconfig = {\"configurable\": {\"thread_id\": \"abc123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob! and i live in sf\")]}, config):    print(chunk)    print(\"----\")for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]}, config):    print(chunk)    print(\"----\")API Reference:ChatAnthropic | TavilySearchResults | HumanMessage | MemorySaver | create_react_agent'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='{\\'agent\\': {\\'messages\\': [AIMessage(content=\"Hello Bob! Since you didn\\'t ask a specific question, I don\\'t need to use any tools to respond. It\\'s nice to meet you. San Francisco is a wonderful city with lots to see and do. I hope you\\'re enjoying living there. Please let me know if you have any other questions!\", response_metadata={\\'id\\': \\'msg_01Mmfzfs9m4XMgVzsCZYMWqH\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 271, \\'output_tokens\\': 65}}, id=\\'run-44c57f9c-a637-4888-b7d9-6d985031ae48-0\\', usage_metadata={\\'input_tokens\\': 271, \\'output_tokens\\': 65, \\'total_tokens\\': 336})]}}----{\\'agent\\': {\\'messages\\': [AIMessage(content=[{\\'text\\': \\'To get current weather information for your location in San Francisco, let me invoke the search tool:\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01BGEyQaSz3pTq8RwUUHSRoo\\', \\'input\\': {\\'query\\': \\'san francisco weather\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}], response_metadata={\\'id\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='tool:\\', \\'type\\': \\'text\\'}, {\\'id\\': \\'toolu_01BGEyQaSz3pTq8RwUUHSRoo\\', \\'input\\': {\\'query\\': \\'san francisco weather\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}], response_metadata={\\'id\\': \\'msg_013AVSVsRLKYZjduLpJBY4us\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'tool_use\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 347, \\'output_tokens\\': 80}}, id=\\'run-de7923b6-5ee2-4ebe-bd95-5aed4933d0e3-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'san francisco weather\\'}, \\'id\\': \\'toolu_01BGEyQaSz3pTq8RwUUHSRoo\\'}], usage_metadata={\\'input_tokens\\': 347, \\'output_tokens\\': 80, \\'total_tokens\\': 427})]}}----{\\'tools\\': {\\'messages\\': [ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1717238643, \\\\\\'localtime\\\\\\': \\\\\\'2024-06-01 3:44\\\\\\'},'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1717238643, \\\\\\'localtime\\\\\\': \\\\\\'2024-06-01 3:44\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1717237800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-06-01 03:30\\\\\\', \\\\\\'temp_c\\\\\\': 12.0, \\\\\\'temp_f\\\\\\': 53.6, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Mist\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/143.png\\\\\\', \\\\\\'code\\\\\\': 1030}, \\\\\\'wind_mph\\\\\\': 5.6, \\\\\\'wind_kph\\\\\\': 9.0, \\\\\\'wind_degree\\\\\\': 310, \\\\\\'wind_dir\\\\\\': \\\\\\'NW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1013.0, \\\\\\'pressure_in\\\\\\': 29.92, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 88, \\\\\\'cloud\\\\\\': 100, \\\\\\'feelslike_c\\\\\\': 10.5, \\\\\\'feelslike_f\\\\\\': 50.8, \\\\\\'windchill_c\\\\\\': 9.3, \\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\': 20.1}}\"}, {\"url\":'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\': 20.1}}\"}, {\"url\": \"https://www.timeanddate.com/weather/usa/san-francisco/historic\", \"content\": \"Past Weather in San Francisco, California, USA \\\\\\\\u2014 Yesterday and Last 2 Weeks. Time/General. Weather. Time Zone. DST Changes. Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 68 \\\\\\\\u00b0F. Passing clouds.\"}]\\', name=\\'tavily_search_results_json\\', tool_call_id=\\'toolu_01BGEyQaSz3pTq8RwUUHSRoo\\')]}}----{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'Based on the search results, the current weather in San Francisco is:\\\\n\\\\nTemperature: 53.6°F (12°C)\\\\nConditions: Misty\\\\nWind: 5.6 mph (9 kph) from the Northwest\\\\nHumidity: 88%\\\\nCloud Cover: 100% \\\\n\\\\nThe results provide detailed information like wind chill, heat index, visibility and more. It looks like a typical cool,'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"5.6 mph (9 kph) from the Northwest\\\\nHumidity: 88%\\\\nCloud Cover: 100% \\\\n\\\\nThe results provide detailed information like wind chill, heat index, visibility and more. It looks like a typical cool, foggy morning in San Francisco. Let me know if you need any other details about the weather where you live!', response_metadata={'id': 'msg_019WGLbaojuNdbCnqac7zaGW', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 1035, 'output_tokens': 120}}, id='run-1bb68bf3-b212-4ef4-8a31-10c830421c78-0', usage_metadata={'input_tokens': 1035, 'output_tokens': 120, 'total_tokens': 1155})]}}----\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Setup\\u200b\\nJupyter Notebook\\u200b\\nThis guide (and most of the other guides in the documentation) uses Jupyter notebooks and assumes the reader is as well. Jupyter notebooks are perfect interactive environments for learning how to work with LLM systems because oftentimes things can go wrong (unexpected output, API down, etc), and observing these cases is a great way to better understand building with LLMs.\\nThis and other tutorials are perhaps most conveniently run in a Jupyter notebook. See here for instructions on how to install.\\nInstallation\\u200b\\nTo install LangChain run:\\n%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite\\nFor more details, see our Installation guide.\\nLangSmith\\u200b\\nMany of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls.\\nAs these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent.\\nThe best way to do this is with LangSmith.\\nAfter you sign up at the link above, make sure to set your environment variables to start logging traces:\\nexport LANGSMITH_TRACING=\"true\"export LANGSMITH_API_KEY=\"...\"\\nOr, if in a notebook, you can set them with:\\nimport getpassimport osos.environ[\"LANGSMITH_TRACING\"] = \"true\"os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()\\nTavily\\u200b\\nWe will be using Tavily (a search engine) as a tool.\\nIn order to use it, you will need to get and set an API key:\\nexport TAVILY_API_KEY=\"...\"\\nOr, if in a notebook, you can set it with:\\nimport getpassimport osos.environ[\"TAVILY_API_KEY\"] = getpass.getpass()\\nDefine tools\\u200b\\nWe first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='We first need to create the tools we want to use. Our main tool of choice will be Tavily - a search engine. We have a built-in tool in LangChain to easily use Tavily search engine as tool.\\nfrom langchain_community.tools.tavily_search import TavilySearchResultssearch = TavilySearchResults(max_results=2)search_results = search.invoke(\"what is the weather in SF\")print(search_results)# If we want, we can create other tools.# Once we have all the tools we want, we can put them in a list that we will reference later.tools = [search]API Reference:TavilySearchResults'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='[{\\'url\\': \\'https://www.weatherapi.com/\\',  \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717238703, \\'localtime\\': \\'2024-06-01 3:45\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717237800, \\'last_updated\\': \\'2024-06-01 03:30\\', \\'temp_c\\': 12.0, \\'temp_f\\': 53.6, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 310, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1013.0, \\'pressure_in\\': 29.92, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 88, \\'cloud\\': 100, \\'feelslike_c\\': 10.5, \\'feelslike_f\\': 50.8, \\'windchill_c\\': 9.3, \\'windchill_f\\': 48.7, \\'heatindex_c\\': 11.1, \\'heatindex_f\\': 51.9, \\'dewpoint_c\\': 8.8, \\'dewpoint_f\\': 47.8, \\'vis_km\\': 6.4, \\'vis_miles\\': 3.0, \\'uv\\': 1.0, \\'gust_mph\\': 12.5, \\'gust_kph\\': 20.1}}\"}, {\\'url\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='9.3, \\'windchill_f\\': 48.7, \\'heatindex_c\\': 11.1, \\'heatindex_f\\': 51.9, \\'dewpoint_c\\': 8.8, \\'dewpoint_f\\': 47.8, \\'vis_km\\': 6.4, \\'vis_miles\\': 3.0, \\'uv\\': 1.0, \\'gust_mph\\': 12.5, \\'gust_kph\\': 20.1}}\"}, {\\'url\\': \\'https://www.wunderground.com/hourly/us/ca/san-francisco/date/2024-01-06\\',  \\'content\\': \\'Current Weather for Popular Cities . San Francisco, CA 58 ° F Partly Cloudy; Manhattan, NY warning 51 ° F Cloudy; Schiller Park, IL (60176) warning 51 ° F Fair; Boston, MA warning 41 ° F ...\\'}]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"Using Language Models\\u200b\\nNext, let's learn how to use a language model to call tools. LangChain supports many different language models that you can use interchangably - select the one you want to use below!\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Select chat model:Groq▾GroqOpenAIAnthropicAzureGoogleAWSCohereNVIDIAFireworks AIMistral AITogether AIDatabrickspip install -qU langchain-groqimport getpassimport osif not os.environ.get(\"GROQ_API_KEY\"):  os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")from langchain_groq import ChatGroqmodel = ChatGroq(model=\"llama3-8b-8192\")\\nYou can call the language model by passing in a list of messages. By default, the response is a content string.\\nfrom langchain_core.messages import HumanMessageresponse = model.invoke([HumanMessage(content=\"hi!\")])response.contentAPI Reference:HumanMessage\\n\\'Hi there!\\'\\nWe can now see what it is like to enable this model to do tool calling. In order to enable that we use .bind_tools to give the language model knowledge of these tools\\nmodel_with_tools = model.bind_tools(tools)\\nWe can now call the model. Let\\'s first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='We can now call the model. Let\\'s first call it with a normal message, and see how it responds. We can look at both the content field as well as the tool_calls field.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: Hello!ToolCalls: []\\nNow, let\\'s try calling it with some input that would expect a tool to be called.\\nresponse = model_with_tools.invoke([HumanMessage(content=\"What\\'s the weather in SF?\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")\\nContentString: ToolCalls: [{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather san francisco\\'}, \\'id\\': \\'toolu_01VTP7DUvSfgtYxsq9x4EwMp\\'}]\\nWe can see that there\\'s now no text content, but there is a tool call! It wants us to call the Tavily Search tool.\\nThis isn\\'t calling that tool yet - it\\'s just telling us to. In order to actually call it, we\\'ll want to create our agent.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"This isn't calling that tool yet - it's just telling us to. In order to actually call it, we'll want to create our agent.\\nCreate the agent\\u200b\\nNow that we have defined the tools and the LLM, we can create the agent. We will be using LangGraph to construct the agent.\\nCurrently, we are using a high level interface to construct the agent, but the nice thing about LangGraph is that this high-level interface is backed by a low-level, highly controllable API in case you want to modify the agent logic.\\nNow, we can initialize the agent with the LLM and the tools.\\nNote that we are passing in the model, not model_with_tools. That is because create_react_agent will call .bind_tools for us under the hood.\\nfrom langgraph.prebuilt import create_react_agentagent_executor = create_react_agent(model, tools)API Reference:create_react_agent\\nRun the agent\\u200b\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='from langgraph.prebuilt import create_react_agentagent_executor = create_react_agent(model, tools)API Reference:create_react_agent\\nRun the agent\\u200b\\nWe can now run the agent with a few queries! Note that for now, these are all stateless queries (it won\\'t remember previous interactions). Note that the agent will return the final state at the end of the interaction (which includes any inputs, we will see later on how to get only the outputs).\\nFirst up, let\\'s see how it responds when there\\'s no need to call a tool:\\nresponse = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})response[\"messages\"]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='First up, let\\'s see how it responds when there\\'s no need to call a tool:\\nresponse = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})response[\"messages\"]\\n[HumanMessage(content=\\'hi!\\', id=\\'a820fcc5-9b87-457a-9af0-f21768143ee3\\'), AIMessage(content=\\'Hello!\\', response_metadata={\\'id\\': \\'msg_01VbC493X1VEDyusgttiEr1z\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 264, \\'output_tokens\\': 5}}, id=\\'run-0e0ddae8-a85b-4bd6-947c-c36c857a4698-0\\', usage_metadata={\\'input_tokens\\': 264, \\'output_tokens\\': 5, \\'total_tokens\\': 269})]\\nIn order to see exactly what is happening under the hood (and to make sure it\\'s not calling a tool) we can take a look at the LangSmith trace\\nLet\\'s now try it out on an example where it should be invoking the tool\\nresponse = agent_executor.invoke(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]})response[\"messages\"]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='[HumanMessage(content=\\'whats the weather in sf?\\', id=\\'1d6c96bb-4ddb-415c-a579-a07d5264de0d\\'), AIMessage(content=[{\\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\', \\'input\\': {\\'query\\': \\'weather in san francisco\\'}, \\'name\\': \\'tavily_search_results_json\\', \\'type\\': \\'tool_use\\'}], response_metadata={\\'id\\': \\'msg_0132wQUcEduJ8UKVVVqwJzM4\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'tool_use\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 269, \\'output_tokens\\': 61}}, id=\\'run-26d5e5e8-d4fd-46d2-a197-87b95b10e823-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weather in san francisco\\'}, \\'id\\': \\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'}], usage_metadata={\\'input_tokens\\': 269, \\'output_tokens\\': 61, \\'total_tokens\\': 330}), ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\','),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1717238703, \\\\\\'localtime\\\\\\': \\\\\\'2024-06-01 3:45\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1717237800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-06-01 03:30\\\\\\', \\\\\\'temp_c\\\\\\': 12.0, \\\\\\'temp_f\\\\\\': 53.6, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Mist\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/143.png\\\\\\', \\\\\\'code\\\\\\': 1030}, \\\\\\'wind_mph\\\\\\': 5.6, \\\\\\'wind_kph\\\\\\': 9.0, \\\\\\'wind_degree\\\\\\': 310, \\\\\\'wind_dir\\\\\\': \\\\\\'NW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1013.0, \\\\\\'pressure_in\\\\\\': 29.92, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 88, \\\\\\'cloud\\\\\\': 100, \\\\\\'feelslike_c\\\\\\': 10.5, \\\\\\'feelslike_f\\\\\\': 50.8, \\\\\\'windchill_c\\\\\\': 9.3, \\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\\\\\\'windchill_f\\\\\\': 48.7, \\\\\\'heatindex_c\\\\\\': 11.1, \\\\\\'heatindex_f\\\\\\': 51.9, \\\\\\'dewpoint_c\\\\\\': 8.8, \\\\\\'dewpoint_f\\\\\\': 47.8, \\\\\\'vis_km\\\\\\': 6.4, \\\\\\'vis_miles\\\\\\': 3.0, \\\\\\'uv\\\\\\': 1.0, \\\\\\'gust_mph\\\\\\': 12.5, \\\\\\'gust_kph\\\\\\': 20.1}}\"}, {\"url\": \"https://www.timeanddate.com/weather/usa/san-francisco/hourly\", \"content\": \"Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 59 \\\\\\\\u00b0F. Passing clouds. (Weather station: San Francisco International Airport, USA). See more current weather.\"}]\\', name=\\'tavily_search_results_json\\', id=\\'37aa1fd9-b232-4a02-bd22-bc5b9b44a22c\\', tool_call_id=\\'toolu_01Y5EK4bw2LqsQXeaUv8iueF\\'), AIMessage(content=\\'Based on the search results, here is a summary of the current weather in San Francisco:\\\\n\\\\nThe weather in San Francisco is currently misty with a temperature of around 53°F (12°C). There is complete cloud cover and moderate winds from the northwest around 5-9 mph (9-14 km/h). Humidity is high at 88%. Visibility is around 3 miles'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"misty with a temperature of around 53°F (12°C). There is complete cloud cover and moderate winds from the northwest around 5-9 mph (9-14 km/h). Humidity is high at 88%. Visibility is around 3 miles (6.4 km). \\\\n\\\\nThe results provide an hourly forecast as well as current conditions from a couple different weather sources. Let me know if you need any additional details about the San Francisco weather!', response_metadata={'id': 'msg_01BRX9mrT19nBDdHYtR7wJ92', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 920, 'output_tokens': 132}}, id='run-d0325583-3ddc-4432-b2b2-d023eb97660f-0', usage_metadata={'input_tokens': 920, 'output_tokens': 132, 'total_tokens': 1052})]\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='We can check out the LangSmith trace to make sure it\\'s calling the search tool effectively.\\nStreaming Messages\\u200b\\nWe\\'ve seen how the agent can be called with .invoke to get  a final response. If the agent executes multiple steps, this may take a while. To show intermediate progress, we can stream back messages as they occur.\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}):    print(chunk)    print(\"----\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'\\', additional_kwargs={\\'tool_calls\\': [{\\'id\\': \\'call_50Kb8zHmFqPYavQwF5TgcOH8\\', \\'function\\': {\\'arguments\\': \\'{\\\\n  \"query\": \"current weather in San Francisco\"\\\\n}\\', \\'name\\': \\'tavily_search_results_json\\'}, \\'type\\': \\'function\\'}]}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 23, \\'prompt_tokens\\': 134, \\'total_tokens\\': 157}, \\'model_name\\': \\'gpt-4\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'tool_calls\\', \\'logprobs\\': None}, id=\\'run-042d5feb-c2cc-4c3f-b8fd-dbc22fd0bc07-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'current weather in San Francisco\\'}, \\'id\\': \\'call_50Kb8zHmFqPYavQwF5TgcOH8\\'}])]}}----{\\'action\\': {\\'messages\\': [ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1714426906,'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\\\\\\'San Francisco\\\\\\', \\\\\\'region\\\\\\': \\\\\\'California\\\\\\', \\\\\\'country\\\\\\': \\\\\\'United States of America\\\\\\', \\\\\\'lat\\\\\\': 37.78, \\\\\\'lon\\\\\\': -122.42, \\\\\\'tz_id\\\\\\': \\\\\\'America/Los_Angeles\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1714426906, \\\\\\'localtime\\\\\\': \\\\\\'2024-04-29 14:41\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1714426200, \\\\\\'last_updated\\\\\\': \\\\\\'2024-04-29 14:30\\\\\\', \\\\\\'temp_c\\\\\\': 17.8, \\\\\\'temp_f\\\\\\': 64.0, \\\\\\'is_day\\\\\\': 1, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Sunny\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/day/113.png\\\\\\', \\\\\\'code\\\\\\': 1000}, \\\\\\'wind_mph\\\\\\': 23.0, \\\\\\'wind_kph\\\\\\': 37.1, \\\\\\'wind_degree\\\\\\': 290, \\\\\\'wind_dir\\\\\\': \\\\\\'WNW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1019.0, \\\\\\'pressure_in\\\\\\': 30.09, \\\\\\'precip_mm\\\\\\': 0.0, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 50, \\\\\\'cloud\\\\\\': 0, \\\\\\'feelslike_c\\\\\\': 17.8, \\\\\\'feelslike_f\\\\\\': 64.0, \\\\\\'vis_km\\\\\\': 16.0, \\\\\\'vis_miles\\\\\\': 9.0, \\\\\\'uv\\\\\\': 5.0, \\\\\\'gust_mph\\\\\\': 27.5, \\\\\\'gust_kph\\\\\\': 44.3}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/april-2024/\", \"content\": \"Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='27.5, \\\\\\'gust_kph\\\\\\': 44.3}}\"}, {\"url\": \"https://world-weather.info/forecast/usa/san_francisco/april-2024/\", \"content\": \"Extended weather forecast in San Francisco. Hourly Week 10 days 14 days 30 days Year. Detailed \\\\\\\\u26a1 San Francisco Weather Forecast for April 2024 - day/night \\\\\\\\ud83c\\\\\\\\udf21\\\\\\\\ufe0f temperatures, precipitations - World-Weather.info.\"}]\\', name=\\'tavily_search_results_json\\', id=\\'d88320ac-3fe1-4f73-870a-3681f15f6982\\', tool_call_id=\\'call_50Kb8zHmFqPYavQwF5TgcOH8\\')]}}----{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'The current weather in San Francisco, California is sunny with a temperature of 17.8°C (64.0°F). The wind is coming from the WNW at 23.0 mph. The humidity is at 50%. [source](https://www.weatherapi.com/)\\', response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 58, \\'prompt_tokens\\': 602, \\'total_tokens\\': 660}, \\'model_name\\': \\'gpt-4\\', \\'system_fingerprint\\': None, \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-0cd2a507-ded5-4601-afe3-3807400e9989-0\\')]}}----'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Streaming tokens\\u200b\\nIn addition to streaming back messages, it is also useful to stream back tokens.\\nWe can do this with the .astream_events method.\\nimportantThis .astream_events method only works with Python 3.11 or higher.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='async for event in agent_executor.astream_events(    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"):    kind = event[\"event\"]    if kind == \"on_chain_start\":        if (            event[\"name\"] == \"Agent\"        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`            print(                f\"Starting agent: {event[\\'name\\']} with input: {event[\\'data\\'].get(\\'input\\')}\"            )    elif kind == \"on_chain_end\":        if (            event[\"name\"] == \"Agent\"        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`            print()            print(\"--\")            print(                f\"Done agent: {event[\\'name\\']} with output: {event[\\'data\\'].get(\\'output\\')[\\'output\\']}\"            )    if kind == \"on_chat_model_stream\":        content = event[\"data\"][\"chunk\"].content        if content:            # Empty content in the context of OpenAI means            # that the model is asking'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='if kind == \"on_chat_model_stream\":        content = event[\"data\"][\"chunk\"].content        if content:            # Empty content in the context of OpenAI means            # that the model is asking for a tool to be invoked.            # So we only print non-empty content            print(content, end=\"|\")    elif kind == \"on_tool_start\":        print(\"--\")        print(            f\"Starting tool: {event[\\'name\\']} with inputs: {event[\\'data\\'].get(\\'input\\')}\"        )    elif kind == \"on_tool_end\":        print(f\"Done tool: {event[\\'name\\']}\")        print(f\"Tool output was: {event[\\'data\\'].get(\\'output\\')}\")        print(\"--\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='--Starting tool: tavily_search_results_json with inputs: {\\'query\\': \\'current weather in San Francisco\\'}Done tool: tavily_search_results_jsonTool output was: [{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1714427052, \\'localtime\\': \\'2024-04-29 14:44\\'}, \\'current\\': {\\'last_updated_epoch\\': 1714426200, \\'last_updated\\': \\'2024-04-29 14:30\\', \\'temp_c\\': 17.8, \\'temp_f\\': 64.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 23.0, \\'wind_kph\\': 37.1, \\'wind_degree\\': 290, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1019.0, \\'pressure_in\\': 30.09, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 50, \\'cloud\\': 0, \\'feelslike_c\\': 17.8, \\'feelslike_f\\': 64.0, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 27.5, \\'gust_kph\\': 44.3}}\"}, {\\'url\\':'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='\\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 50, \\'cloud\\': 0, \\'feelslike_c\\': 17.8, \\'feelslike_f\\': 64.0, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 5.0, \\'gust_mph\\': 27.5, \\'gust_kph\\': 44.3}}\"}, {\\'url\\': \\'https://www.weathertab.com/en/c/e/04/united-states/california/san-francisco/\\', \\'content\\': \\'San Francisco Weather Forecast for Apr 2024 - Risk of Rain Graph. Rain Risk Graph: Monthly Overview. Bar heights indicate rain risk percentages. Yellow bars mark low-risk days, while black and grey bars signal higher risks. Grey-yellow bars act as buffers, advising to keep at least one day clear from the riskier grey and black days, guiding ...\\'}]--The| current| weather| in| San| Francisco|,| California|,| USA| is| sunny| with| a| temperature| of| |17|.|8|°C| (|64|.|0|°F|).| The| wind| is| blowing| from| the| W|NW| at| a| speed| of| |37|.|1| k|ph| (|23|.|0| mph|).| The| humidity| level| is| at| |50|%.| [|Source|](|https|://|www|.weather|api|.com|/)|'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='Adding in memory\\u200b\\nAs mentioned earlier, this agent is stateless. This means it does not remember previous interactions. To give it memory we need to pass in a checkpointer. When passing in a checkpointer, we also have to pass in a thread_id when invoking the agent (so it knows which thread/conversation to resume from).\\nfrom langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()API Reference:MemorySaver\\nagent_executor = create_react_agent(model, tools, checkpointer=memory)config = {\"configurable\": {\"thread_id\": \"abc123\"}}\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config):    print(chunk)    print(\"----\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"Hello Bob! It\\'s nice to meet you again.\", response_metadata={\\'id\\': \\'msg_013C1z2ZySagEFwmU1EsysR2\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1162, \\'output_tokens\\': 14}}, id=\\'run-f878acfd-d195-44e8-9166-e2796317e3f8-0\\', usage_metadata={\\'input_tokens\\': 1162, \\'output_tokens\\': 14, \\'total_tokens\\': 1176})]}}----\\nfor chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\\'You mentioned your name is Bob when you introduced yourself earlier. So your name is Bob.\\', response_metadata={\\'id\\': \\'msg_01WNwnRNGwGDRw6vRdivt6i1\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 1184, \\'output_tokens\\': 21}}, id=\\'run-f5c0b957-8878-405a-9d4b-a7cd38efe81f-0\\', usage_metadata={\\'input_tokens\\': 1184, \\'output_tokens\\': 21, \\'total_tokens\\': 1205})]}}----\\nExample LangSmith trace\\nIf you want to start a new conversation, all you have to do is change the thread_id used\\nconfig = {\"configurable\": {\"thread_id\": \"xyz123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content='config = {\"configurable\": {\"thread_id\": \"xyz123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config):    print(chunk)    print(\"----\")\\n{\\'agent\\': {\\'messages\\': [AIMessage(content=\"I\\'m afraid I don\\'t actually know your name. As an AI assistant without personal information about you, I don\\'t have a specific name associated with our conversation.\", response_metadata={\\'id\\': \\'msg_01NoaXNNYZKSoBncPcLkdcbo\\', \\'model\\': \\'claude-3-sonnet-20240229\\', \\'stop_reason\\': \\'end_turn\\', \\'stop_sequence\\': None, \\'usage\\': {\\'input_tokens\\': 267, \\'output_tokens\\': 36}}, id=\\'run-c9f7df3d-525a-4d8f-bbcf-a5b4a5d2e4b0-0\\', usage_metadata={\\'input_tokens\\': 267, \\'output_tokens\\': 36, \\'total_tokens\\': 303})]}}----\\nConclusion\\u200b\\nThat\\'s a wrap! In this quick start we covered how to create a simple agent.\\nWe\\'ve then shown how to stream back a response - not only with the intermediate steps, but also tokens!\\nWe\\'ve also added in memory so you can have a conversation with them.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/tutorials/agents/', 'title': 'Build an Agent | 🦜️🔗 LangChain', 'description': \"By themselves, language models can't take actions - they just output text.\", 'language': 'en'}, page_content=\"We've then shown how to stream back a response - not only with the intermediate steps, but also tokens!\\nWe've also added in memory so you can have a conversation with them.\\nAgents are a complex topic with lots to learn!\\nFor more information on Agents, please check out the LangGraph documentation. This has it's own set of concepts, tutorials, and how-to guides.Edit this pageWas this page helpful?PreviousBuild an Extraction ChainNextTaggingEnd-to-end agentSetupJupyter NotebookInstallationLangSmithTavilyDefine toolsUsing Language ModelsCreate the agentRun the agentStreaming MessagesStreaming tokensAdding in memoryConclusionCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright © 2025 LangChain, Inc.\")]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "document = text_splitter.split_documents(document)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x10eab3020>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(document,embeddings)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Using Language Models\\u200b\\nNext, let's learn how to use a language model to call tools. LangChain supports many different language models that you can use interchangably - select the one you want to use below!\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"This application will translate text from English to another language\"\n",
    "result = vectorstore.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader =PyPDFLoader(\"/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf\")\n",
    "imageloader = PyPDFLoader(\"/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 0, 'page_label': '1'}, page_content='Agentic AI\\nGenAI&\\nWith Cloud'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 1, 'page_label': '2'}, page_content=\"This course is designed for AI enthusiasts and professionals eager to dive into the world of Agentic\\nAI and Natural Language Processing (NLP). You will gain hands-on experience in building\\nintelligent systems, mastering NLP techniques, developing agentic decision-making frameworks,\\nand implementing state-of-the-art GenAI solutions. By the end, you'll be proficient in creating,\\ndeploying, and monitoring advanced NLP and agentic applications.\\nLearning Objectives\\nBuild a solid understanding of Natural Language Processing (NLP) techniques and\\ntheir applications in AI systems.\\nImplement and optimize NLP models for tasks like text classification, sentiment\\nanalysis, and named entity recognition using libraries like SpaCy and Hugging Face.\\nExplore Generative AI (GenAI) techniques, including transformers and language\\nmodels, for generating and completing text tasks.\\nDevelop agentic systems by learning multi-agent collaboration, decision-making\\nframeworks, and feedback loops in complex environments.\\nMaster retrieval-augmented generation (RAG) for improving information retrieval and\\ngeneration tasks in NLP applications.\\nApply state-of-the-art frameworks like LangChain and LangFlow to build scalable and\\nefficient NLP workflows.\\nBuild and deploy conversational agents and chatbots using LangGraph, LangFlow,\\nand integration with third-party tools and APIs.\\nUnderstand and apply observability techniques for monitoring LLMs and agentic\\nsystems, leveraging tools like Langfuse and LangWatch.\\nAgentic And GenAI       Page  2\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 2, 'page_label': '3'}, page_content='Course Information\\nPython : Proficiency in Python fundamentals, including variables, data types, control\\nstructures, and libraries like NumPy, Pandas, and Matplotlib for data manipulation and\\nvisualization.\\nNLP : Experience with Python libraries like NLTK, SpaCy, and TextBlob for text\\npreprocessing, tokenization, stemming, lemmatization, and machine learning concepts like\\nclassification and vectorization.\\nGenAI : Knowledge of Python, deep learning frameworks (TensorFlow, PyTorch), and\\nGenerative AI models like transformers, GANs, and VAEs, along with data manipulation skills\\nusing NumPy and Pandas.\\nAgentic And GenAI       Page  3\\nEstimated Time\\n5 months 6hrs/week*\\nRequired Skill Level\\nBegineer+\\nThe course is designed to be completed over a duration of approximately four to five months,\\nproviding an in-depth exploration of agentic AI and NLP concepts, with plenty of time for practical\\nimplementation and real-world applications.\\nPrerequisites'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 3, 'page_label': '4'}, page_content='Course Instructors\\nAgentic And GenAI       Page  4\\nSourangshu PalSenior Data Scientist\\nLinkedin\\nSunny SavitaGenAI Engineer\\nLinkedin\\nKrish NaikChief AI Engineer\\nLinkedin\\nMayank AggrawalSenior ML Engineer\\nLinkedin'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 4, 'page_label': '5'}, page_content='In this module, we’ll explore the fundamentals of Agentic AI, including what defines an agent, how\\nit differs from traditional AI agents and generative AI, and the role of multi-agents in problem-\\nsolving. You’ll learn about various frameworks used in Agentic AI, which enable the creation,\\nmanagement, and orchestration of intelligent agents. This foundational knowledge will set the\\nstage for understanding the broader applications and evolution of agent-based systems in AI and\\nhow they can be leveraged for complex decision-making, automation, and problem-solving tasks.\\nAgentic And GenAI       Page  5\\nIntroduction to Agentic AI\\nModule 1\\nTopics\\nWhat is Agentic AI? What are Agents?, Agentic AI vs AI\\nAgents, Agentic AI vs Generative AI,\\nWhat are Multi-Agents?\\nAgentic AI Frameworks Overview of Agentic AI Frameworks'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 5, 'page_label': '6'}, page_content='Module 2\\nThis module introduces Phi Data as a powerful framework for building Agentic AI systems. You’ll\\nlearn how to integrate agents with various models, tools, and knowledge sources. Topics covered\\ninclude the essential concepts of chunking, vector databases, and embedding techniques that\\nform the backbone of Agentic AI. The module also covers the design and execution of workflows,\\nenabling you to create intelligent agents that process and retrieve data efficiently. We’ll explore\\nreal-world use cases such as web search agents, financial agents, and retrieval-augmented\\ngeneration (RAG) agents to understand how these concepts are applied in practice.\\nAgentic And GenAI      Page  6\\nPhi Data: Agentic AI Framework\\nTopics\\nCore Concepts Agents in Phi Data, Models, Tools,\\nKnowledge, Chunking\\nData and Storage Vector Databases (VectorDbs), Storage,\\nEmbeddings\\nWorkflows Workflow Design and Execution\\nUse Cases Web Search Agents, Financial Agents,\\nRetrieval-Augmented Generation (RAG)\\nAgents'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 6, 'page_label': '7'}, page_content=\"Module 3\\nIn this module, we dive into LangChain, a framework that simplifies the creation of complex AI\\napplications using LLMs (Large Language Models). You will learn how to use LangChain's\\ncomponents for data ingestion, document loaders, and text splitting techniques to prepare data\\nfor processing. Additionally, we cover how to work with embeddings from various sources such as\\nOpenAI, Ollama, and Hugging Face, and integrate them with vector storage systems like FAISS\\nand ChromaDB. By the end of this module, you'll have a deep understanding of how to structure,\\nprocess, and store data within LangChain for use in AI models and agents.\\nAgentic And GenAI       Page  7\\nLangChain\\nTopics\\nCore Components and Data Handling Introduction to Basic Components and\\nModules in LangChain, Data Ingestion\\nwith Document Loaders\\nText Splitting Techniques Recursive Character Text Splitter,\\nCharacter Text Splitter, HTML Header\\nText Splitter, Recursive JSON Splitter\\nEmbeddings and Vector Storage OpenAI Embeddings, Ollama\\nEmbeddings, Hugging Face\\nEmbeddings, VectorStores: FAISS and\\nChromaDB, VectorStore and Retriever\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 7, 'page_label': '8'}, page_content='Module 4\\nAgentic And GenAI       Page  8\\nLCEL (LangChain Expression Language)\\nTopics\\nGetting Started Open Source Models Using Groq API\\nBuilding and Deploying Building LLMs, Prompt and Structured\\nOutput Chains with LCEL, Deploying\\nLangServe Runnables and Chains as\\nAPIs\\nThis module focuses on LangChain Expression Language (LCEL), which allows you to work with\\nLLMs more effectively. You’ll learn how to get started with open-source models using the Groq\\nAPI and how to build and optimize language models (LLMs). The module also covers the creation\\nof prompt and output chains with LCEL to create efficient workflows and decision-making\\nprocesses for intelligent agents. Lastly, we will explore how to deploy LangServe runnables and\\nchains as APIs, enabling you to create production-ready agentic AI solutions that can scale across\\nvarious platforms and use cases.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 8, 'page_label': '9'}, page_content=\"Module 5\\nIn this module, we explore LangServe, a powerful framework that streamlines the deployment of\\nAI models for production environments. You will learn how to deploy and scale AI applications\\nefficiently using LangServe's robust features, ensuring smooth integrations with cloud platforms\\nand optimization of resources for large-scale AI tasks.\\nAgentic And GenAI       Page  9\\nLangServe for Efficient AI Deployment\\nTopics\\nOverview and Setup Overview of LangServe and Its\\nCapabilities, Importance of Efficient AI\\nModel Serving, Key Features and\\nBenefits of LangServe, Setting Up the\\nLangServe Environment, Installing\\nLangServe and Initial Configuration,\\nConfiguring Environment Variables and\\nDependencies\\nModel Deployment API-Driven Model Serving: How\\nLangServe Bridges AI Models and\\nApplications, Deploying Your Model with\\nLangServe, Creating and Managing\\nCustom Endpoints, Integrations with\\nExternal Tools\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 9, 'page_label': '10'}, page_content='Module 6\\nThis module covers LangGraph, a framework that enables complex AI workflows. You will learn\\nhow to structure and manage state within LangGraph applications, handle deployments, and\\nunderstand the integration of various components for building scalable AI systems, with an\\nemphasis on state management and deployment strategies.\\nAgentic And GenAI       Page  10\\nLangGraph\\nTopics\\nCore Concepts Introduction, Simple Graph, LangGraph\\nStudio, Chain, Router\\nAgents Agent, Agent with Memory, Intro to\\nDeployment\\nState Concepts State Schema, State Reducers, Multiple\\nSchemas\\nMessage Handling Trim and Filter Messages\\nDeployment Concepts Deployment Concepts, Creating and\\nConnecting to Deployment'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 10, 'page_label': '11'}, page_content='Module 7\\nThis module focuses on creating human-in-the-loop workflows with LangGraph, where you will\\nlearn how to enhance user experiences in AI applications by integrating human feedback loops,\\noptimizing AI outputs, and improving system interaction based on real-time user inputs.\\nAgentic And GenAI       Page  11\\nUX and Human-in-the-Loop with\\nLangGraph\\nTopics\\nInteraction Streaming, Breakpoints, Editing State\\nand Human Feedback, Dynamic\\nBreakpoints\\nTime Travel Time Travel'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 11, 'page_label': '12'}, page_content='Module 8\\nIn this module, you will learn the principles of Agentic Retrieval-Augmented Generation (RAG), a\\ntechnique that enhances AI agent capabilities by retrieving external data and combining it with\\ngenerated content. The focus will be on creating agents that can autonomously retrieve and\\ngenerate relevant information for improved performance.\\nAgentic And GenAI       Page  12\\nAgentic RAG\\nTopics\\nAdaptive RAG Adaptive Rag, Adaptive Rag with\\nCohere, Adaptive rag in Local\\nRAG Variants Agentic Rag, C-Rag, C-Rag in Local, Self\\nRag, Self Rag in Local, Self Rag with\\nVectorDB'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 12, 'page_label': '13'}, page_content=\"Module 9\\nThis module delves into the design of multi-agent systems within LangGraph, where you will learn\\nto build systems with multiple AI agents that can collaborate, share information, and solve\\ncomplex problems together. You'll also explore agent communication and coordination\\nmechanisms for efficient system performance.\\nAgentic And GenAI       Page  13\\nDesigning Multi-Agent Systems with\\nLangGraph\\nTopics\\nAgent Design Building Agent Nodes in LangGraph,\\nAgent Communication Protocols and\\nCoordination, Defining Tasks and Roles\\nfor Agents\\nSystem Design Creating Scalable Multi-Agent Systems\\nin LangGraph, Building A Real-World\\nMulti-Agent System\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 13, 'page_label': '14'}, page_content='In this module, you will get an introduction to the CrewAI platform, a solution for creating and\\nmanaging AI teams or agents. You will learn how to leverage CrewAI to coordinate and automate\\nworkflows involving multiple AI agents, optimizing collaborative tasks and decision-making.\\nAgentic And GenAI       Page  14\\nCrewAI Platform\\nTopics\\nOverview Definition and Overview, Key Features\\nand Capabilities, Crew Collaboration\\nFramework\\nCollaboration and Tools AI-Agent Communication, Workflow\\nAutomation in CrewAI, Customizing\\nCrewAI, Managing Data Across Agents,\\nRole-playing, Memory, Tools, Focus,\\nGuardrails, Cooperation, Using\\nLangChain Tools\\nModule 10'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 14, 'page_label': '15'}, page_content='This module introduces LangFlow, a framework for creating and managing AI-driven flows. You\\nwill learn how to set up LangFlow for efficient workflow management, build AI-driven applications\\nusing its various components, and integrate different models seamlessly to automate tasks within\\na flow.\\nAgentic And GenAI       Page  15\\nLangFlow Overview and Setup\\nTopics\\nIntroduction and Setup What is LangFlow? Overview and Use\\nCases, Key Features of LangFlow for\\nLLM Applications, Setting Up Your\\nLangFlow Environment\\nLangFlow UI and Terminologies Understanding LangFlow UI and\\nWorkflows, Key Terminologies in\\nLangFlow (Nodes, Chains, Prompts)\\nQuick Start Quick Start: Creating Your First\\nLangFlow Application\\nCore Concepts Nodes and Chains: Core Concepts,\\nUnderstanding LLMs and Their\\nIntegration with LangFlow, Pre-built vs.\\nCustom Workflows\\nModule 11'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 15, 'page_label': '16'}, page_content='Agentic And GenAI       Page  16\\nLangFlow Overview and Setup\\nTopics\\nLangChain and Prompt Engineering Prompt Engineering Basics in LangFlow,\\nLangChain Integration: Using LangFlow\\nwith LangChain\\nCommonly Used Nodes Exploring Commonly Used LangFlow\\nNodes\\nModule 11'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 16, 'page_label': '17'}, page_content='In this module, we explore how to integrate LangChain and LangGraph with third-party tools and\\nservices. You will learn to extend AI workflows by connecting them to external APIs, databases,\\nand other platforms, allowing for seamless data exchange and enhanced functionality in your AI\\nprojects.\\nAgentic And GenAI       Page  17\\nIntegration with Third-Party Tools\\nTopics\\nData Integration Connecting LangFlow with Data Sources\\n(SQL, CSV, NoSQL), Using LangFlow\\nwith Vector Databases for Embeddings\\nAPI Integration API Integration for External Services\\n(REST, GraphQL), LangFlow with OpenAI\\nand Hugging Face Models\\nWorkflow Automation Automating Workflows Using LangFlow,\\nBuilding Chatbot Applications with\\nLangFlow\\nModule 12'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 17, 'page_label': '18'}, page_content=\"This module covers Langfuse, a tool for tracking and monitoring large language model (LLM)\\nperformance. You will learn how to use Langfuse for observability, tracking model outputs,\\nanalyzing system performance, and identifying areas for optimization, ensuring that LLMs operate\\nat their best.\\nAgentic And GenAI       Page  18\\nLangfuse for LLM Observability\\nTopics\\nLangfuse Overview What is Langfuse? Overview and\\nApplications, Importance of Observability\\nin LLMs, Key Features and Benefits of\\nLangfuse, Understanding Langfuse's\\nIntegration Ecosystem\\nIntegration and Monitoring Step-by-Step Integration with Popular\\nFrameworks (LangChain, OpenAI, etc.),\\nSetting Up API Calls for Observability,\\nTracking Key Metrics: Response Times,\\nCosts, and Errors, Monitoring Prompt\\nEffectiveness and Token Usage\\nModule 13\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 18, 'page_label': '19'}, page_content='In this module, you will explore LangWatch, a monitoring tool for LangChain applications. You will\\nlearn how to track and analyze key metrics in real-time, gain insights into the health and\\nperformance of AI models, and ensure system reliability through effective monitoring strategies.\\nAgentic And GenAI       Page  19\\nMetrics and Monitoring in LangWatch\\nTopics\\nLangWatch Overview What is LangWatch? Overview and Use\\nCases, Key Features of LangWatch in\\nMonitoring Language Models,\\nConnecting LangWatch with LLMs\\nAPI Integration and Setup API Integration: Sending Logs and Data\\nto LangWatch, Setting Up Observability\\nin AI Workflows\\nUsing LangWatch with Frameworks Using LangWatch with Popular\\nFrameworks\\nModule 14'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 19, 'page_label': '20'}, page_content=\"This module introduces Langsmith, a platform for enhancing and testing AI models. You will learn\\nhow to leverage Langsmith's features to refine and improve model outputs, test different model\\nversions, and evaluate performance under varying conditions to ensure optimal AI model behavior.\\nAgentic And GenAI       Page  20\\nLangsmith\\nTopics\\nLangsmith Overview What is LangSmith? Overview and Key\\nFeatures, LangSmith in the AI\\nDevelopment Workflow\\nSetup and Configuration Setting Up LangSmith: Installation and\\nConfiguration, Exploring the User\\nInterface and Core Functionalities\\nWorkflow Management Understanding Workflow Pipelines in\\nLangSmith, Creating and Managing AI\\nWorkflows, Data Integration in\\nLangSmith, Preprocessing and Cleaning\\nData, Managing Data Streams and\\nSources\\nModule 15\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 20, 'page_label': '21'}, page_content='This module introduces Autogen, an automated system for generating AI models. You will learn\\nhow Autogen simplifies model creation and tuning, allowing you to generate robust AI models\\nfaster and with minimal manual input, while maintaining high levels of performance and accuracy.\\nAgentic And GenAI       Page  21\\nIntroduction to Autogen\\nTopics\\nFramework Overview Overview,Key Concepts: Autonomy,\\nAdaptability, and Inter-Agent\\nCommunication, Installation and\\nEnvironment Setup\\nAgentic System Development Introduction to Agents, Goals,\\nEnvironments, and Actions, APIs,\\nLibraries, and Tools Available Within the\\nAutogen Framework, Designing and\\nDeveloping Agentic Systems, Framework\\nfor Agentic Decision-Making\\nAgent Interaction and Learning Interaction and Communication\\nBetween Agents, Implementing\\nFeedback Loops, Handling Uncertainty\\nand Constraints, Agent Learning and\\nAdaptation, Multi-Agent Collaboration\\nModule 16'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 21, 'page_label': '22'}, page_content='Agentic And GenAI       Page  22\\nIntroduction to Autogen\\nTopics\\nDeployment and Monitoring Deployment, Monitoring Agent\\nPerformance\\nModule 16'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 22, 'page_label': '23'}, page_content='Agentic And GenAI       Page  23\\nEnd to End Agentic AI Projects\\nTopics\\nProject-Based Learning Agentic AI Projects\\nModule 17\\nIn this module, we guide you through the process of creating end-to-end agentic AI projects,\\nwhere you will learn how to build, deploy, and optimize autonomous AI agents that perform real-\\nworld tasks, incorporating data retrieval, processing, and decision-making within a unified AI\\nsystem.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 23, 'page_label': '24'}, page_content='Topics\\nIntroduction to AWS Cloud Detail introduction of AWS Cloud\\nservices, How to create an AWS\\naccount, How to create an IAM,\\nUnderstanding Regions and Zones\\nAWS Compute and Container\\nServices\\nAWS Elastic Container Registry, AWS\\nElastic Cloud Compute, AWS App\\nRunner\\nModule 18\\nThis module provides an introduction to AWS Cloud services, with a focus on deploying and\\nmanaging generative AI models. You will learn how to use AWS services like EC2, S3, SageMaker,\\nand Lambda for building, training, and scaling generative AI applications.\\nAWS Cloud & Services for Generative AI\\nAgentic And GenAI       Page  24'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 24, 'page_label': '25'}, page_content='Topics\\nIntroduction to AWS Bedrock Amazon Bedrock - Introduction, Bedrock\\nConsole Walkthrough, Amazon Bedrock\\n- Architecture\\nBedrock Models and Use Cases Bedrock Foundation Models, Bedrock\\nEmbeddings, Bedrock Chat Playgrounds\\nBedrock Inference and Pricing Amazon Bedrock - Inference Parameters,\\nBedrock Pricing\\nAWS Bedrock\\nAgentic And GenAI       Page  25\\nModule 19\\nIn this module, we explore AWS Bedrock, a service for foundation models. You will learn how to\\nuse Bedrock for building and deploying large-scale AI models, with an emphasis on leveraging its\\ninference capabilities, model types, and integration with other AWS services for seamless AI\\ndeployments.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 25, 'page_label': '26'}, page_content=\"Topics\\nOverview of AWS SageMaker AWS SageMaker Overview, AWS\\nSageMaker Walk-through, AWS\\nSageMaker Studio Overview, AWS\\nSageMaker Studio Walk-through\\nModel Deployment with SageMaker Choose a Pre-trained Model, SageMaker\\nEndpoint Creation, SageMaker Console\\nAccess, Create SageMaker Domain,\\nOpen SageMaker Studio, SageMaker\\nModels Deployment\\nAWS SageMaker\\nAgentic And GenAI       Page  26\\nModule 20\\nThis module introduces AWS SageMaker, a comprehensive machine learning platform. You will\\nlearn how to use SageMaker for end-to-end ML development, including model training,\\ndeployment, and monitoring. Additionally, you'll explore SageMaker Studio for streamlined\\nworkflow management and optimization of AI models.\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 26, 'page_label': '27'}, page_content='Topics\\nOverview of AWS Lambda Overview of AWS Lambda, Lambda\\nConsole Walkthrough, Lambda\\nPermissions Model\\nAWS Lambda\\nAgentic And GenAI       Page  27\\nModule 21\\nThis module focuses on AWS Lambda, a serverless compute service. You will learn how to create,\\ndeploy, and manage serverless functions using Lambda, as well as how to integrate it with other\\nAWS services for automated workflows, reducing infrastructure management overhead.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 27, 'page_label': '28'}, page_content='Topics\\nAPI Gateway Overview AWS API Gateway, RESTful APIs,\\nWebSocket APIs\\nEfficient API Development Efficient API Development\\nAWS API Gateway\\nAgentic And GenAI       Page  28\\nModule 22\\nIn this module, you will learn about AWS API Gateway, a service for building APIs. You will explore\\nhow to create RESTful and WebSocket APIs, integrate them with AWS Lambda, and use them for\\nefficient AI application development, ensuring scalable and reliable API management.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 28, 'page_label': '29'}, page_content='Topics\\nIntegration of AWS Lambda with\\nBedrock and API Gateway\\nCreation of AWS Lambda function and\\nBoto3 upgrade, Writing the AWS\\nLambda function to connect to Bedrock\\nService, Create REST API using AWS API\\nGateway and Lambda Integration\\nText Summarization with AWS Services\\nAgentic And GenAI       Page  29\\nModule 23\\nThis module guides you through creating text summarization applications using AWS Lambda and\\nAPI Gateway, integrated with Bedrock services. You will learn how to set up Lambda functions,\\nconnect them to Bedrock, and expose a RESTful API for summarizing text efficiently.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 29, 'page_label': '30'}, page_content='Topics\\nFine-Tuning Overview Fine-Tuning of Foundation Model -\\nOverview, Fine-Tuning of Foundation\\nModel - Architecture\\nHands-On with AWS SageMaker Fine-Tuning of Foundation Models -\\nHands On AWS SageMaker\\nFine-Tuning Foundation Models on\\nCustom Data\\nAgentic And GenAI       Page  30\\nModule 24\\nIn this module, you will learn how to fine-tune pre-trained foundation models on your own custom\\ndata using AWS SageMaker. You will explore the steps involved in preparing data, configuring\\nmodels, and performing training to optimize performance for specific use cases.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 30, 'page_label': '31'}, page_content='Topics\\nRetrieval-Augmented Generation\\n(RAG) in AWS\\nOverview, Setup, Data Transformation\\nand Processing, LLM and Retrieval QA,\\nFrontend and Backend Development\\nBuilding Chatbot with Llama3,\\nLangchain & Streamlit\\nOverview, Setup, Data Handling and LLM\\nCreation, Frontend and Final Demo\\nProject : AWS\\nAgentic And GenAI       Page  31\\nModule 25\\nThis module combines the creation of a Retrieval-Augmented Generation (RAG) system and a\\nchatbot using Llama3, Langchain, and Streamlit. You will learn how to build a fully integrated\\nproject that combines data retrieval with natural language generation to provide intelligent\\nconversational agents.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 31, 'page_label': '32'}, page_content=\"Topics\\nIntroduction to Google Cloud and\\nVertex AI\\nWhat is Vertex AI?, Google AI Studio\\nIntroduction, Google Cloud Regions &\\nZones, Foundation Google Models\\nVertex AI Setup and Installation Vertex AI Installation, Google Cloud\\nSetup for Production, Vertex AI\\nOverview, Vertex AI Model Garden\\nGCP Basics & Introduction to Vertex AI\\nAgentic And GenAI       Page  32\\nModule 26\\nThis module introduces Google Cloud's Vertex AI, a platform for building and deploying AI models.\\nYou will learn the basics of Vertex AI, including setup, model management, and integration with\\nGoogle Cloud’s infrastructure, enabling efficient AI solutions in the cloud.\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 32, 'page_label': '33'}, page_content='Topics\\nIntroduction to Google Gemini What is Google Gemini?, Google Gemini:\\nPlaying with Gemini, Gemini 1.5 Pro\\n(Preview only), Gemini 1.0 Pro\\nGemini Embeddings and Retrieval Gemini Embeddings, Advanced\\nInformation Retrieval with Gemini\\nWorking with Prompts Working with Freeform & Structured\\nprompts, Working with Text Chat prompt\\nMultimodal and Text-Based Use\\nCases\\nGenerate Code, Unit test with Code\\nChat Bison model, Translate text with\\nTranslation LLM, Summarization,\\nClassification\\nMultimodal Applications Vision Model, Speech to Text & Text to\\nSpeech, Multimodal Prompts\\nGemini Models with Vertex AI and\\nGoogle AI Studio\\nAgentic And GenAI       Page  33\\nModule 27\\nThis module explores Google Gemini models and their integration with Vertex AI and Google AI\\nStudio. You will learn how to leverage these models for advanced AI applications, utilizing the AI\\nStudio’s features for building, deploying, and managing Gemini-based AI projects.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 33, 'page_label': '34'}, page_content='Topics\\nRetrieval-Augmented Generation\\n(RAG) in GCP\\nOverview, Setup, Data Transformation\\nand LLM Context, Frontend and Final\\nDemo\\nBuilding Chatbot with Gemini Pro,\\nLangchain & Streamlit in GCP\\nOverview, Setup, Data Transformation\\nand LLM Creation, Frontend and Final\\nDemo\\nProject : GCP\\nAgentic And GenAI      Page  34\\nModule 28\\nThis module combines the implementation of Retrieval-Augmented Generation (RAG) in GCP\\nwith building a chatbot using Gemini Pro, Langchain, and Streamlit. You will learn how to integrate\\nRAG and build an intelligent conversational system using these technologies for enhanced\\ninteractivity.')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages = loader.load_and_split()\n",
    "pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 0, 'page_label': '1'}, page_content='Agentic AI\\nGenAI&\\nWith Cloud'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 1, 'page_label': '2'}, page_content=\"This course is designed for AI enthusiasts and professionals eager to dive into the world of Agentic\\nAI and Natural Language Processing (NLP). You will gain hands-on experience in building\\nintelligent systems, mastering NLP techniques, developing agentic decision-making frameworks,\\nand implementing state-of-the-art GenAI solutions. By the end, you'll be proficient in creating,\\ndeploying, and monitoring advanced NLP and agentic applications.\\nLearning Objectives\\nBuild a solid understanding of Natural Language Processing (NLP) techniques and\\ntheir applications in AI systems.\\nImplement and optimize NLP models for tasks like text classification, sentiment\\nanalysis, and named entity recognition using libraries like SpaCy and Hugging Face.\\nExplore Generative AI (GenAI) techniques, including transformers and language\\nmodels, for generating and completing text tasks.\\nDevelop agentic systems by learning multi-agent collaboration, decision-making\\nframeworks, and feedback loops in complex environments.\\nMaster retrieval-augmented generation (RAG) for improving information retrieval and\\ngeneration tasks in NLP applications.\\nApply state-of-the-art frameworks like LangChain and LangFlow to build scalable and\\nefficient NLP workflows.\\nBuild and deploy conversational agents and chatbots using LangGraph, LangFlow,\\nand integration with third-party tools and APIs.\\nUnderstand and apply observability techniques for monitoring LLMs and agentic\\nsystems, leveraging tools like Langfuse and LangWatch.\\nAgentic And GenAI       Page  2\\n\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 2, 'page_label': '3'}, page_content='Course Information\\nPython : Proficiency in Python fundamentals, including variables, data types, control\\nstructures, and libraries like NumPy, Pandas, and Matplotlib for data manipulation and\\nvisualization.\\nNLP : Experience with Python libraries like NLTK, SpaCy, and TextBlob for text\\npreprocessing, tokenization, stemming, lemmatization, and machine learning concepts like\\nclassification and vectorization.\\nGenAI : Knowledge of Python, deep learning frameworks (TensorFlow, PyTorch), and\\nGenerative AI models like transformers, GANs, and VAEs, along with data manipulation skills\\nusing NumPy and Pandas.\\nAgentic And GenAI       Page  3\\nEstimated Time\\n5 months 6hrs/week*\\nRequired Skill Level\\nBegineer+\\nThe course is designed to be completed over a duration of approximately four to five months,\\nproviding an in-depth exploration of agentic AI and NLP concepts, with plenty of time for practical\\nimplementation and real-world applications.\\nPrerequisites'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 3, 'page_label': '4'}, page_content='Course Instructors\\nAgentic And GenAI       Page  4\\nSourangshu PalSenior Data Scientist\\nLinkedin\\nSunny SavitaGenAI Engineer\\nLinkedin\\nKrish NaikChief AI Engineer\\nLinkedin\\nMayank AggrawalSenior ML Engineer\\nLinkedin'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 4, 'page_label': '5'}, page_content='In this module, we’ll explore the fundamentals of Agentic AI, including what defines an agent, how\\nit differs from traditional AI agents and generative AI, and the role of multi-agents in problem-\\nsolving. You’ll learn about various frameworks used in Agentic AI, which enable the creation,\\nmanagement, and orchestration of intelligent agents. This foundational knowledge will set the\\nstage for understanding the broader applications and evolution of agent-based systems in AI and\\nhow they can be leveraged for complex decision-making, automation, and problem-solving tasks.\\nAgentic And GenAI       Page  5\\nIntroduction to Agentic AI\\nModule 1\\nTopics\\nWhat is Agentic AI? What are Agents?, Agentic AI vs AI\\nAgents, Agentic AI vs Generative AI,\\nWhat are Multi-Agents?\\nAgentic AI Frameworks Overview of Agentic AI Frameworks\\n'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 5, 'page_label': '6'}, page_content='Module 2\\nThis module introduces Phi Data as a powerful framework for building Agentic AI systems. You’ll\\nlearn how to integrate agents with various models, tools, and knowledge sources. Topics covered\\ninclude the essential concepts of chunking, vector databases, and embedding techniques that\\nform the backbone of Agentic AI. The module also covers the design and execution of workflows,\\nenabling you to create intelligent agents that process and retrieve data efficiently. We’ll explore\\nreal-world use cases such as web search agents, financial agents, and retrieval-augmented\\ngeneration (RAG) agents to understand how these concepts are applied in practice.\\nAgentic And GenAI      Page  6\\nPhi Data: Agentic AI Framework\\nTopics\\nCore Concepts Agents in Phi Data, Models, Tools,\\nKnowledge, Chunking\\nData and Storage Vector Databases (VectorDbs), Storage,\\nEmbeddings\\nWorkflows Workflow Design and Execution\\nUse Cases Web Search Agents, Financial Agents,\\nRetrieval-Augmented Generation (RAG)\\nAgents\\n'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 6, 'page_label': '7'}, page_content=\"Module 3\\nIn this module, we dive into LangChain, a framework that simplifies the creation of complex AI\\napplications using LLMs (Large Language Models). You will learn how to use LangChain's\\ncomponents for data ingestion, document loaders, and text splitting techniques to prepare data\\nfor processing. Additionally, we cover how to work with embeddings from various sources such as\\nOpenAI, Ollama, and Hugging Face, and integrate them with vector storage systems like FAISS\\nand ChromaDB. By the end of this module, you'll have a deep understanding of how to structure,\\nprocess, and store data within LangChain for use in AI models and agents.\\nAgentic And GenAI       Page  7\\nLangChain\\nTopics\\nCore Components and Data Handling Introduction to Basic Components and\\nModules in LangChain, Data Ingestion\\nwith Document Loaders\\nText Splitting Techniques Recursive Character Text Splitter,\\nCharacter Text Splitter, HTML Header\\nText Splitter, Recursive JSON Splitter\\nEmbeddings and Vector Storage OpenAI Embeddings, Ollama\\nEmbeddings, Hugging Face\\nEmbeddings, VectorStores: FAISS and\\nChromaDB, VectorStore and Retriever\\n\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 7, 'page_label': '8'}, page_content='Module 4\\nAgentic And GenAI       Page  8\\nLCEL (LangChain Expression Language)\\nTopics\\nGetting Started Open Source Models Using Groq API\\nBuilding and Deploying Building LLMs, Prompt and Structured\\nOutput Chains with LCEL, Deploying\\nLangServe Runnables and Chains as\\nAPIs\\nThis module focuses on LangChain Expression Language (LCEL), which allows you to work with\\nLLMs more effectively. You’ll learn how to get started with open-source models using the Groq\\nAPI and how to build and optimize language models (LLMs). The module also covers the creation\\nof prompt and output chains with LCEL to create efficient workflows and decision-making\\nprocesses for intelligent agents. Lastly, we will explore how to deploy LangServe runnables and\\nchains as APIs, enabling you to create production-ready agentic AI solutions that can scale across\\nvarious platforms and use cases.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 8, 'page_label': '9'}, page_content=\"Module 5\\nIn this module, we explore LangServe, a powerful framework that streamlines the deployment of\\nAI models for production environments. You will learn how to deploy and scale AI applications\\nefficiently using LangServe's robust features, ensuring smooth integrations with cloud platforms\\nand optimization of resources for large-scale AI tasks.\\nAgentic And GenAI       Page  9\\nLangServe for Efficient AI Deployment\\nTopics\\nOverview and Setup Overview of LangServe and Its\\nCapabilities, Importance of Efficient AI\\nModel Serving, Key Features and\\nBenefits of LangServe, Setting Up the\\nLangServe Environment, Installing\\nLangServe and Initial Configuration,\\nConfiguring Environment Variables and\\nDependencies\\nModel Deployment API-Driven Model Serving: How\\nLangServe Bridges AI Models and\\nApplications, Deploying Your Model with\\nLangServe, Creating and Managing\\nCustom Endpoints, Integrations with\\nExternal Tools\\n\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 9, 'page_label': '10'}, page_content='Module 6\\nThis module covers LangGraph, a framework that enables complex AI workflows. You will learn\\nhow to structure and manage state within LangGraph applications, handle deployments, and\\nunderstand the integration of various components for building scalable AI systems, with an\\nemphasis on state management and deployment strategies.\\nAgentic And GenAI       Page  10\\nLangGraph\\nTopics\\nCore Concepts Introduction, Simple Graph, LangGraph\\nStudio, Chain, Router\\nAgents Agent, Agent with Memory, Intro to\\nDeployment\\nState Concepts State Schema, State Reducers, Multiple\\nSchemas\\nMessage Handling Trim and Filter Messages\\nDeployment Concepts Deployment Concepts, Creating and\\nConnecting to Deployment\\n'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 10, 'page_label': '11'}, page_content='Module 7\\nThis module focuses on creating human-in-the-loop workflows with LangGraph, where you will\\nlearn how to enhance user experiences in AI applications by integrating human feedback loops,\\noptimizing AI outputs, and improving system interaction based on real-time user inputs.\\nAgentic And GenAI       Page  11\\nUX and Human-in-the-Loop with\\nLangGraph\\nTopics\\nInteraction Streaming, Breakpoints, Editing State\\nand Human Feedback, Dynamic\\nBreakpoints\\nTime Travel Time Travel\\n'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 11, 'page_label': '12'}, page_content='Module 8\\nIn this module, you will learn the principles of Agentic Retrieval-Augmented Generation (RAG), a\\ntechnique that enhances AI agent capabilities by retrieving external data and combining it with\\ngenerated content. The focus will be on creating agents that can autonomously retrieve and\\ngenerate relevant information for improved performance.\\nAgentic And GenAI       Page  12\\nAgentic RAG\\nTopics\\nAdaptive RAG Adaptive Rag, Adaptive Rag with\\nCohere, Adaptive rag in Local\\nRAG Variants Agentic Rag, C-Rag, C-Rag in Local, Self\\nRag, Self Rag in Local, Self Rag with\\nVectorDB\\n'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 12, 'page_label': '13'}, page_content=\"Module 9\\nThis module delves into the design of multi-agent systems within LangGraph, where you will learn\\nto build systems with multiple AI agents that can collaborate, share information, and solve\\ncomplex problems together. You'll also explore agent communication and coordination\\nmechanisms for efficient system performance.\\nAgentic And GenAI       Page  13\\nDesigning Multi-Agent Systems with\\nLangGraph\\nTopics\\nAgent Design Building Agent Nodes in LangGraph,\\nAgent Communication Protocols and\\nCoordination, Defining Tasks and Roles\\nfor Agents\\nSystem Design Creating Scalable Multi-Agent Systems\\nin LangGraph, Building A Real-World\\nMulti-Agent System\\n\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 13, 'page_label': '14'}, page_content='In this module, you will get an introduction to the CrewAI platform, a solution for creating and\\nmanaging AI teams or agents. You will learn how to leverage CrewAI to coordinate and automate\\nworkflows involving multiple AI agents, optimizing collaborative tasks and decision-making.\\nAgentic And GenAI       Page  14\\nCrewAI Platform\\nTopics\\nOverview Definition and Overview, Key Features\\nand Capabilities, Crew Collaboration\\nFramework\\nCollaboration and Tools AI-Agent Communication, Workflow\\nAutomation in CrewAI, Customizing\\nCrewAI, Managing Data Across Agents,\\nRole-playing, Memory, Tools, Focus,\\nGuardrails, Cooperation, Using\\nLangChain Tools\\nModule 10'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 14, 'page_label': '15'}, page_content='This module introduces LangFlow, a framework for creating and managing AI-driven flows. You\\nwill learn how to set up LangFlow for efficient workflow management, build AI-driven applications\\nusing its various components, and integrate different models seamlessly to automate tasks within\\na flow.\\nAgentic And GenAI       Page  15\\nLangFlow Overview and Setup\\nTopics\\nIntroduction and Setup What is LangFlow? Overview and Use\\nCases, Key Features of LangFlow for\\nLLM Applications, Setting Up Your\\nLangFlow Environment\\nLangFlow UI and Terminologies Understanding LangFlow UI and\\nWorkflows, Key Terminologies in\\nLangFlow (Nodes, Chains, Prompts)\\nQuick Start Quick Start: Creating Your First\\nLangFlow Application\\nCore Concepts Nodes and Chains: Core Concepts,\\nUnderstanding LLMs and Their\\nIntegration with LangFlow, Pre-built vs.\\nCustom Workflows\\nModule 11'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 15, 'page_label': '16'}, page_content='Agentic And GenAI       Page  16\\nLangFlow Overview and Setup\\nTopics\\nLangChain and Prompt Engineering Prompt Engineering Basics in LangFlow,\\nLangChain Integration: Using LangFlow\\nwith LangChain\\nCommonly Used Nodes Exploring Commonly Used LangFlow\\nNodes\\nModule 11'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 16, 'page_label': '17'}, page_content='In this module, we explore how to integrate LangChain and LangGraph with third-party tools and\\nservices. You will learn to extend AI workflows by connecting them to external APIs, databases,\\nand other platforms, allowing for seamless data exchange and enhanced functionality in your AI\\nprojects.\\nAgentic And GenAI       Page  17\\nIntegration with Third-Party Tools\\nTopics\\nData Integration Connecting LangFlow with Data Sources\\n(SQL, CSV, NoSQL), Using LangFlow\\nwith Vector Databases for Embeddings\\nAPI Integration API Integration for External Services\\n(REST, GraphQL), LangFlow with OpenAI\\nand Hugging Face Models\\nWorkflow Automation Automating Workflows Using LangFlow,\\nBuilding Chatbot Applications with\\nLangFlow\\nModule 12'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 17, 'page_label': '18'}, page_content=\"This module covers Langfuse, a tool for tracking and monitoring large language model (LLM)\\nperformance. You will learn how to use Langfuse for observability, tracking model outputs,\\nanalyzing system performance, and identifying areas for optimization, ensuring that LLMs operate\\nat their best.\\nAgentic And GenAI       Page  18\\nLangfuse for LLM Observability\\nTopics\\nLangfuse Overview What is Langfuse? Overview and\\nApplications, Importance of Observability\\nin LLMs, Key Features and Benefits of\\nLangfuse, Understanding Langfuse's\\nIntegration Ecosystem\\nIntegration and Monitoring Step-by-Step Integration with Popular\\nFrameworks (LangChain, OpenAI, etc.),\\nSetting Up API Calls for Observability,\\nTracking Key Metrics: Response Times,\\nCosts, and Errors, Monitoring Prompt\\nEffectiveness and Token Usage\\nModule 13\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 18, 'page_label': '19'}, page_content='In this module, you will explore LangWatch, a monitoring tool for LangChain applications. You will\\nlearn how to track and analyze key metrics in real-time, gain insights into the health and\\nperformance of AI models, and ensure system reliability through effective monitoring strategies.\\nAgentic And GenAI       Page  19\\nMetrics and Monitoring in LangWatch\\nTopics\\nLangWatch Overview What is LangWatch? Overview and Use\\nCases, Key Features of LangWatch in\\nMonitoring Language Models,\\nConnecting LangWatch with LLMs\\nAPI Integration and Setup API Integration: Sending Logs and Data\\nto LangWatch, Setting Up Observability\\nin AI Workflows\\nUsing LangWatch with Frameworks Using LangWatch with Popular\\nFrameworks\\nModule 14'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 19, 'page_label': '20'}, page_content=\"This module introduces Langsmith, a platform for enhancing and testing AI models. You will learn\\nhow to leverage Langsmith's features to refine and improve model outputs, test different model\\nversions, and evaluate performance under varying conditions to ensure optimal AI model behavior.\\nAgentic And GenAI       Page  20\\nLangsmith\\nTopics\\nLangsmith Overview What is LangSmith? Overview and Key\\nFeatures, LangSmith in the AI\\nDevelopment Workflow\\nSetup and Configuration Setting Up LangSmith: Installation and\\nConfiguration, Exploring the User\\nInterface and Core Functionalities\\nWorkflow Management Understanding Workflow Pipelines in\\nLangSmith, Creating and Managing AI\\nWorkflows, Data Integration in\\nLangSmith, Preprocessing and Cleaning\\nData, Managing Data Streams and\\nSources\\nModule 15\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 20, 'page_label': '21'}, page_content='This module introduces Autogen, an automated system for generating AI models. You will learn\\nhow Autogen simplifies model creation and tuning, allowing you to generate robust AI models\\nfaster and with minimal manual input, while maintaining high levels of performance and accuracy.\\nAgentic And GenAI       Page  21\\nIntroduction to Autogen\\nTopics\\nFramework Overview Overview,Key Concepts: Autonomy,\\nAdaptability, and Inter-Agent\\nCommunication, Installation and\\nEnvironment Setup\\nAgentic System Development Introduction to Agents, Goals,\\nEnvironments, and Actions, APIs,\\nLibraries, and Tools Available Within the\\nAutogen Framework, Designing and\\nDeveloping Agentic Systems, Framework\\nfor Agentic Decision-Making\\nAgent Interaction and Learning Interaction and Communication\\nBetween Agents, Implementing\\nFeedback Loops, Handling Uncertainty\\nand Constraints, Agent Learning and\\nAdaptation, Multi-Agent Collaboration\\nModule 16'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 21, 'page_label': '22'}, page_content='Agentic And GenAI       Page  22\\nIntroduction to Autogen\\nTopics\\nDeployment and Monitoring Deployment, Monitoring Agent\\nPerformance\\nModule 16'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 22, 'page_label': '23'}, page_content='Agentic And GenAI       Page  23\\nEnd to End Agentic AI Projects\\nTopics\\nProject-Based Learning Agentic AI Projects\\nModule 17\\nIn this module, we guide you through the process of creating end-to-end agentic AI projects,\\nwhere you will learn how to build, deploy, and optimize autonomous AI agents that perform real-\\nworld tasks, incorporating data retrieval, processing, and decision-making within a unified AI\\nsystem.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 23, 'page_label': '24'}, page_content='Topics\\nIntroduction to AWS Cloud Detail introduction of AWS Cloud\\nservices, How to create an AWS\\naccount, How to create an IAM,\\nUnderstanding Regions and Zones\\nAWS Compute and Container\\nServices\\nAWS Elastic Container Registry, AWS\\nElastic Cloud Compute, AWS App\\nRunner\\nModule 18\\nThis module provides an introduction to AWS Cloud services, with a focus on deploying and\\nmanaging generative AI models. You will learn how to use AWS services like EC2, S3, SageMaker,\\nand Lambda for building, training, and scaling generative AI applications.\\nAWS Cloud & Services for Generative AI\\nAgentic And GenAI       Page  24'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 24, 'page_label': '25'}, page_content='Topics\\nIntroduction to AWS Bedrock Amazon Bedrock - Introduction, Bedrock\\nConsole Walkthrough, Amazon Bedrock\\n- Architecture\\nBedrock Models and Use Cases Bedrock Foundation Models, Bedrock\\nEmbeddings, Bedrock Chat Playgrounds\\nBedrock Inference and Pricing Amazon Bedrock - Inference Parameters,\\nBedrock Pricing\\nAWS Bedrock\\nAgentic And GenAI       Page  25\\nModule 19\\nIn this module, we explore AWS Bedrock, a service for foundation models. You will learn how to\\nuse Bedrock for building and deploying large-scale AI models, with an emphasis on leveraging its\\ninference capabilities, model types, and integration with other AWS services for seamless AI\\ndeployments.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 25, 'page_label': '26'}, page_content=\"Topics\\nOverview of AWS SageMaker AWS SageMaker Overview, AWS\\nSageMaker Walk-through, AWS\\nSageMaker Studio Overview, AWS\\nSageMaker Studio Walk-through\\nModel Deployment with SageMaker Choose a Pre-trained Model, SageMaker\\nEndpoint Creation, SageMaker Console\\nAccess, Create SageMaker Domain,\\nOpen SageMaker Studio, SageMaker\\nModels Deployment\\nAWS SageMaker\\nAgentic And GenAI       Page  26\\nModule 20\\nThis module introduces AWS SageMaker, a comprehensive machine learning platform. You will\\nlearn how to use SageMaker for end-to-end ML development, including model training,\\ndeployment, and monitoring. Additionally, you'll explore SageMaker Studio for streamlined\\nworkflow management and optimization of AI models.\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 26, 'page_label': '27'}, page_content='Topics\\nOverview of AWS Lambda Overview of AWS Lambda, Lambda\\nConsole Walkthrough, Lambda\\nPermissions Model\\nAWS Lambda\\nAgentic And GenAI       Page  27\\nModule 21\\nThis module focuses on AWS Lambda, a serverless compute service. You will learn how to create,\\ndeploy, and manage serverless functions using Lambda, as well as how to integrate it with other\\nAWS services for automated workflows, reducing infrastructure management overhead.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 27, 'page_label': '28'}, page_content='Topics\\nAPI Gateway Overview AWS API Gateway, RESTful APIs,\\nWebSocket APIs\\nEfficient API Development Efficient API Development\\nAWS API Gateway\\nAgentic And GenAI       Page  28\\nModule 22\\nIn this module, you will learn about AWS API Gateway, a service for building APIs. You will explore\\nhow to create RESTful and WebSocket APIs, integrate them with AWS Lambda, and use them for\\nefficient AI application development, ensuring scalable and reliable API management.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 28, 'page_label': '29'}, page_content='Topics\\nIntegration of AWS Lambda with\\nBedrock and API Gateway\\nCreation of AWS Lambda function and\\nBoto3 upgrade, Writing the AWS\\nLambda function to connect to Bedrock\\nService, Create REST API using AWS API\\nGateway and Lambda Integration\\nText Summarization with AWS Services\\nAgentic And GenAI       Page  29\\nModule 23\\nThis module guides you through creating text summarization applications using AWS Lambda and\\nAPI Gateway, integrated with Bedrock services. You will learn how to set up Lambda functions,\\nconnect them to Bedrock, and expose a RESTful API for summarizing text efficiently.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 29, 'page_label': '30'}, page_content='Topics\\nFine-Tuning Overview Fine-Tuning of Foundation Model -\\nOverview, Fine-Tuning of Foundation\\nModel - Architecture\\nHands-On with AWS SageMaker Fine-Tuning of Foundation Models -\\nHands On AWS SageMaker\\nFine-Tuning Foundation Models on\\nCustom Data\\nAgentic And GenAI       Page  30\\nModule 24\\nIn this module, you will learn how to fine-tune pre-trained foundation models on your own custom\\ndata using AWS SageMaker. You will explore the steps involved in preparing data, configuring\\nmodels, and performing training to optimize performance for specific use cases.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 30, 'page_label': '31'}, page_content='Topics\\nRetrieval-Augmented Generation\\n(RAG) in AWS\\nOverview, Setup, Data Transformation\\nand Processing, LLM and Retrieval QA,\\nFrontend and Backend Development\\nBuilding Chatbot with Llama3,\\nLangchain & Streamlit\\nOverview, Setup, Data Handling and LLM\\nCreation, Frontend and Final Demo\\nProject : AWS\\nAgentic And GenAI       Page  31\\nModule 25\\nThis module combines the creation of a Retrieval-Augmented Generation (RAG) system and a\\nchatbot using Llama3, Langchain, and Streamlit. You will learn how to build a fully integrated\\nproject that combines data retrieval with natural language generation to provide intelligent\\nconversational agents.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 31, 'page_label': '32'}, page_content=\"Topics\\nIntroduction to Google Cloud and\\nVertex AI\\nWhat is Vertex AI?, Google AI Studio\\nIntroduction, Google Cloud Regions &\\nZones, Foundation Google Models\\nVertex AI Setup and Installation Vertex AI Installation, Google Cloud\\nSetup for Production, Vertex AI\\nOverview, Vertex AI Model Garden\\nGCP Basics & Introduction to Vertex AI\\nAgentic And GenAI       Page  32\\nModule 26\\nThis module introduces Google Cloud's Vertex AI, a platform for building and deploying AI models.\\nYou will learn the basics of Vertex AI, including setup, model management, and integration with\\nGoogle Cloud’s infrastructure, enabling efficient AI solutions in the cloud.\"),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 32, 'page_label': '33'}, page_content='Topics\\nIntroduction to Google Gemini What is Google Gemini?, Google Gemini:\\nPlaying with Gemini, Gemini 1.5 Pro\\n(Preview only), Gemini 1.0 Pro\\nGemini Embeddings and Retrieval Gemini Embeddings, Advanced\\nInformation Retrieval with Gemini\\nWorking with Prompts Working with Freeform & Structured\\nprompts, Working with Text Chat prompt\\nMultimodal and Text-Based Use\\nCases\\nGenerate Code, Unit test with Code\\nChat Bison model, Translate text with\\nTranslation LLM, Summarization,\\nClassification\\nMultimodal Applications Vision Model, Speech to Text & Text to\\nSpeech, Multimodal Prompts\\nGemini Models with Vertex AI and\\nGoogle AI Studio\\nAgentic And GenAI       Page  33\\nModule 27\\nThis module explores Google Gemini models and their integration with Vertex AI and Google AI\\nStudio. You will learn how to leverage these models for advanced AI applications, utilizing the AI\\nStudio’s features for building, deploying, and managing Gemini-based AI projects.'),\n",
       " Document(metadata={'source': '/Users/jamadagnikotamsetty/MyCode/AgenticAIWorkspace/Agentic And GenAI AWS GCP.pdf', 'page': 33, 'page_label': '34'}, page_content='Topics\\nRetrieval-Augmented Generation\\n(RAG) in GCP\\nOverview, Setup, Data Transformation\\nand LLM Context, Frontend and Final\\nDemo\\nBuilding Chatbot with Gemini Pro,\\nLangchain & Streamlit in GCP\\nOverview, Setup, Data Transformation\\nand LLM Creation, Frontend and Final\\nDemo\\nProject : GCP\\nAgentic And GenAI      Page  34\\nModule 28\\nThis module combines the implementation of Retrieval-Augmented Generation (RAG) in GCP\\nwith building a chatbot using Gemini Pro, Langchain, and Streamlit. You will learn how to integrate\\nRAG and build an intelligent conversational system using these technologies for enhanced\\ninteractivity.')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages1 = imageloader.load()\n",
    "pages1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatMessagePromptTemplate\n",
    "prompt = ChatMessagePromptTemplate.from_template(\"\"\"Answer the followin based on the context\n",
    "                                                 <context>\n",
    "                                                 {}\n",
    "                                                 </context\n",
    "                                                 \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "document_chain = create_stuff_documents_chain(llm,prompt)\n",
    "document_chain\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
